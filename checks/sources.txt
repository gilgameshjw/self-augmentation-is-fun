[{'url': 'https://blog.hum.works/posts/trending-in-ai-new-architectures-and-deeper-reasoning', 'raw_content': 'Hum - Trending in AI: New Architectures and Deeper Reasoning\nSearch\nArtificial intelligence (AI) has seen massive advances in recent years, largely driven by new neural network architectures like transformers that power chatbots and large language models (LLMs). But as impressive as today\'s AI systems may be, they still lack robust reasoning abilities and struggle with complex multimodal inputs like images, figures, and text together.\nChoosing the right models\n, or the right mix of models, is key to driving innovation today, but exciting\nnew startups and research initiatives are already working to create more versatile, polymathic AI architectures that will push these boundaries.\nIn Hum’s newest whitepaper,\nThe Bright Future of AI\n, we explored two key trends in play to make AI systems smarter and less narrow: New model architectures designed for scientific multimodal data, and efforts to move beyond reactive responses to deliberate, human-like reasoning.\nTackling Multimodal Scientific Data\nMuch of the recent progress in AI has come from supervised learning on narrow datasets like news articles and Wikipedia. This has resulted in powerful but specialized systems that falter when confronted with complex, multimodal data like research papers and scientific corpora.\nA startup called\nPolymathic\nis working to overcome this, developing versatile foundation models that can understand and generate scientific data encompassing text, images, figures, and more.\nThis requires architecting model architectures specially designed for such data. Rather than treating modalities like text and images separately, Polymathic research aims to unite them in a joint embedding space. Their models are directly trained on target corpora from science and engineering to capture intrinsic relationships between modalities.\nThis represents a promising evolution beyond today\'s LLMs which struggle when data includes images, charts, and other non-text inputs. Early indications suggest these polymathic models may develop something closer to actual understanding of scientific phenomena compared to generic LLMs.\nThe success of Polymathic and companies working on similar models could massively expand the usefulness of AI for scientists, researchers, and other technical professions. Models that grasp concepts, not just words, may enable a new class of AI assistants, tutors, and lab partners. If models can demonstrate comprehension and ability to communicate expertly on technical subjects, they could even help democratize access to scientific knowledge.\nNew Architectures for Reasoning: System 1 to System 2 Thinking\nToday\'s largest AI models like GPT-3 are reactive systems with effectively fixed compute budgets. This allows them to respond quickly, but it means they don’t deeply search for solutions or contemplate problems. The Nobel prize-winning psychologist Daniel Kahneman characterized this type of snap judgment as "System 1" thinking in his book\nThinking Fast and Slow\n.\nHumans function in "System 2" thinking, meaning we devote more energy for deliberate analytical thinking and reasoning. We leverage this for planning, problem-solving, and parsing complex concepts. Most current AI models cannot be given a problem and "think on it" for an arbitrary amount of time.\nBut some specialized AI systems\ndo\nfeature more robust reasoning in narrow domains. Game-playing algorithms search future move sequences, while robot navigation systems plan paths. These work best in constrained environments, where planning utilizes hardcoded assumptions about the world. General problem solving requires flexible world models that humans intuitively develop through life experience.\nOpenAI and others are investigating how to equip AI agents with such inner world models they can leverage for reasoning and planning. This could enable imagining solutions, breaking down high-level goals into tractable steps, and even simple common sense. With sufficiently robust models, systems could be asked to solve problems without predefined domains and search over hypothetical plans.\nArchitectures that support complex scene and world modeling remain largely theoretical but would vastly expand AI capabilities. Less reactive and more deliberative systems could mean assistants that study requests or tutors that work step-by-step. The shift from System 1 to System 2 is critical for enabling more general intelligence going forward.\nAre you ready for the Future of AI?\nAs AI expands and companies lay the foundations for future reasoning engines, we’ll begin to see models grow more versatile and deliberative, genuinely grasping concepts instead of just recognizing patterns. The next generation of architectures could yield polymathic assistants able to collaborate with humans more as partners rather than just convenient tools.\nTo explore other trends publishers need to know for an AI future,\ndownload a copy\nof The Bright Future of AI.\nYou might like\nGrowth\nCase Study: CRA Drives 1,000+ New Newsletter Sign-ups Using Data\nJohn Challice\nMar 01, 2023\nGrowth\nCase Study: Silverchair Uses Data to Identify Marketing Leads\nJake Minturn\nFeb 16, 2023\nGrowth\nHow Can Publishers Build Relationships with Their Readers?\nLaura Simis\nMay 10, 2022\nTechnology\nZero-Party to Third-Party Data: What\'s the Difference?\nEvan O\'Neill\nNov 04, 2022\nYou might like\nGrowth\nCase Study: CRA Drives 1,000+ New Newsletter Sign-ups Using Data\nJohn Challice\nMar 01, 2023\nGrowth\nCase Study: Silverchair Uses Data to Identify Marketing Leads\nJake Minturn\nFeb 16, 2023\nGrowth\nHow Can Publishers Build Relationships with Their Readers?\nLaura Simis\nMay 10, 2022\nTechnology\nZero-Party to Third-Party Data: What\'s the Difference?\nEvan O\'Neill\nNov 04, 2022\nLink copied', 'image_urls': [], 'title': 'Hum - Trending in AI: New Architectures and Deeper Reasoning'}, {'url': 'https://businessengineer.ai/p/30-rising-ai-startups-to-keep-an', 'raw_content': '30+ Rising AI Startups to Keep An Eye On In 2025\nThe Business Engineer\nSubscribe\nSign in\nShare this post\nThe Business Engineer\n30+ Rising AI Startups to Keep An Eye On In 2025\nCopy link\nFacebook\nEmail\nNotes\nMore\n30+ Rising AI Startups to Keep An Eye On In 2025\nGennaro Cuofano\nDec 26, 2024\n∙ Paid\n37\nShare this post\nThe Business Engineer\n30+ Rising AI Startups to Keep An Eye On In 2025\nCopy link\nFacebook\nEmail\nNotes\nMore\n5\nShare\nWhat’s a good mental model to understand where we’re going next in AI ecosystem development?\nThe AI Convergence explains which areas will be critical to look at in the next 10-30 years:\nThe Business Engineer is a reader-supported publication. To receive new posts and support my work, consider becoming a free or paid subscriber.\nSubscribe\nThe AI Convergence\nGennaro Cuofano\n·\nOctober 31, 2024\nMany people mistakenly view the current AI paradigm as “another new industry.”\nRead full story\nIn the three layers of AI\n,\nThis post is for paid subscribers\nSubscribe\nAlready a paid subscriber?\nSign in\nPrevious\nNext\nShare\nCopy link\nFacebook\nEmail\nNotes\nMore\nThis site requires JavaScript to run correctly. Please\nturn on JavaScript\nor unblock scripts', 'image_urls': [{'url': 'https://substackcdn.com/image/fetch/w_1300,h_650,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F92487293-796a-4c19-82f9-0e8031a37d4c_4280x3228.png', 'score': 1}], 'title': '30+ Rising AI Startups to Keep An Eye On In 2025'}, {'url': 'https://cbi-www.lighthouse.ai/research/report/artificial-intelligence-top-startups-2024/', 'raw_content': "AI 100: The most promising artificial intelligence startups of 2024 - CB Insights Research\nThe AI 100 is CB Insights' annual list of the top private AI companies in the world. From new AI architectures to precision manufacturing, this year’s winners are tackling some of the hardest challenges across industries.\nCB Insights is launching the 8th annual AI 100 — a ranking of the 100 most promising private AI companies in the world.\nHighlights from the 2024 cohort include:\n16 countries\nrepresented, from the US to France to South Africa\n30+ categories of solutions\n, from foundation models to humanoids\n68% early-stage\nstartups\nbuilding virtual worlds, autonomous factories, language models for under-represented languages, and more\n600+ business relationships\nsince 2016 with industry leaders like Toyota, Netflix, and the World Bank\nOur research team picked winning companies based on CB Insights datasets including deal activity, industry partnerships, team strength, investor strength, patent activity, and\nproprietary Mosaic Scores\n. We also analyzed CB Insights’ exclusive\ninterviews with software buyers\nand dug into\nAnalyst Briefings\nsubmitted directly to us by startups.\nPlease click to enlarge.\nCB Insights customers can\ninteract with the entire AI 100 list here\nand view a detailed category breakdown using the\nExpert Collection\n.\nFREE DOWNLOAD: THE COMPLETE AI 100 LIST\nDive deep into the data on this year’s winners, including product focus, investors, key people, and funding.\nFirst name\nLast name\nEmail\nCompany Name\nJob Title\nPhone number\n2024 AI 100 COHORT HIGHLIGHTS\nFunding distribution\nThe cohort has raised over $28B across 240+ equity deals since 2020 (as of 3/22/24).\nOpenAI\nhas raised over 40% of that total, with $12B. Meanwhile, 25% of the winning companies have raised less than $10M, with some not having raised any venture funding.\nJust over two-thirds (68%) of winning companies\nare in the early stages of fundraising (seed/angel and Series A) or have yet to raise outside equity.\nValuation trends\nThis year’s list includes 19 unicorns with a $1B+ valuation.\nMeanwhile,\nSakana AI\n— founded by one of the authors of the\nseminal Google research paper on Transformers\n— has the highest valuation per employee, at $67M. (It had just 3 employees when it earned its $200M valuation in early 2024.\n) Sakana is working on new “nature-inspired” AI architectures and recently released 3 Japanese-language models.\nRevenue generation\nThe AI 100 includes a mix of companies at different stages of maturity, product development, and revenue.\nHugging Face\n, an AI infrastructure platform focused on open-source development, has one of the highest revenue multiples at 150x ($30M in 2023 revenue at a $4.5B valuation). It’s followed by\nPerplexity\n,\nwhich is developing an alternative to traditional search engines, at 65x (based on a 2023 valuation of $520M and $8M in 2024 ARR).\nMidjourney\n, an image generation platform that has not raised any outside equity, is one of the\nleading AI 100 winners by revenue with\n$200M in ARR\n.\nGlobal reach\nA total of 31 winning companies in this year’s cohort are headquartered outside the United States, across 15 other countries. This includes South Africa-based\nLelapa AI\n— which is developing language processing tools for sub-Saharan African languages like Afrikaans, isiZulu, and Sesotho — and Canada-based\nIdeogram\n, which is tackling the problem of generating images with legible text.\nEurope-based startups account for 19% of the list, including companies headquartered in the United Kingdom, France, and Germany.\nCategories & applications\nOver one-third of this year’s winners are focused on building core AI infrastructure, from foundation models to AI chips to AI development platforms.\nA total of 30 vendors are focused on horizontal (i.e., cross-industry) solutions like coding automation, creator tools, and search, while 34 companies are specializing in verticals like gaming, healthcare, education, and manufacturing.\nA handful of winners are building niche applications where the use of AI is not yet commonplace. These include:\nAtomic Industries\n, which is developing AI for tool and die making in manufacturing and is backed by the venture arms of Porsche, Yamaha, and Toyota\nRosebud AI\n, a text-to-game generation startup backed by OpenAI co-founders Ilya Sutskever and Andrej Karpathy, as well as Khosla Ventures\nFlawless AI\n, a startup developing lip-synced video dubbing for the film industry\nCB Insights customers can get\nreal-time updates on the AI 100 winners using this home feed\n.\nIf you aren’t already a client,\nsign up for a free trial\nto learn more about our platform.\nYou might also like:\nWhat’s next for AI agents? 4 trends to watch in 2025\nThe Future of Open vs Closed AI Models: Which should Enterprises Adopt – and Why?\nThe future of the customer journey: AI agents take control of the buying process\nYou might also like:\nWhat’s next for AI agents? 4 trends to watch in 2025\nThe Future of Open vs Closed AI Models: Which should Enterprises Adopt – and Why?\nThe future of the customer journey: AI agents take control of the buying process", 'image_urls': [{'url': 'https://research-assets.cbinsights.com/2024/04/04093450/AI100-DesignedMM-032024_final-1024x771.png', 'score': 1}, {'url': 'https://research-assets.cbinsights.com/2024/03/25135839/AI-100_-Top-companies-by-equity-funding-v2-1024x496.png', 'score': 1}, {'url': 'https://research-assets.cbinsights.com/2024/03/25093702/AI-100_-Valuation-per-employee-1024x542.png', 'score': 1}, {'url': 'https://research-assets.cbinsights.com/2024/03/25093112/AI-100_-Revenue-multiple-by-company-1024x501.png', 'score': 1}], 'title': 'AI 100: The most promising artificial intelligence startups of 2024 - CB Insights Research'}, {'url': 'https://www.forbes.com/lists/ai50/', 'raw_content': "Forbes 2024 AI 50 List - Top Artificial Intelligence Startups\nThe AI 50 2024\nEDITED BY\nKENRICK CAI\nAPRIL 11, 2024, 06:30 AM\nBy spring of 2023, the massive popularity of apps like ChatGPT had prompted a mass scramble among businesses trying to implement the latest advances in generative artificial intelligence. One year later, the craze continues. In turn, a new tech economy has emerged to help businesses develop and deploy AI-powered apps. That’s reflected by the makeup of Forbes’ sixth annual AI 50, produced in partnership with Sequoia and Meritech Capital, which recognizes the most promising privately-held artificial intelligence companies.\nThe use cases are wide-ranging and far-reaching, as immediately evident from the three largest companies on the list in terms of valuation. Model maker OpenAI ($86 billion) counts customers from Morgan Stanley to the government of Iceland, while its rival Anthropic ($18.4 billion, as Forbes reported) is used by Bridgewater and the Boston Consulting Group. Databricks ($43 billion) sells its data analytics and AI deployment software to Shell and the United States Postal Service. For the startups on AI 50, the technology has evolved from capturing customers’ imaginations to capturing billions of dollars in collective revenue.\nThey have also captured the attention of Silicon Valley investors at a time when the fundraising market continues to pose difficulty for other once-hot sectors. The companies on this year’s AI 50 have raised a total of $34.7 billion in funding. Nearly one-third of that total comes from OpenAI, thanks to some $10 billion from Microsoft. Much more comes from other ascendant AI research firms like Anthropic ($7.7 billion raised), Cohere ($445 million) and Mistral AI ($528 million). Underlying them are a slew of infrastructure tools that are helping companies to implement the technology. Many, like Baseten, LangChain and Unstructured, make their debuts on AI 50 after celebrating booming growth metrics in 2023.\nOther forms of AI development are seeing traction too. Take Anduril, which has raised $2.8 billion for defense tech; Insitro, which stockpiled a $643 million cash pile for drug discovery; or Figure AI, which raised $754 million to create humanoid robots. Then, there are companies that are seamlessly layering the latest advances in AI into their own apps. Abridge uses voice recognition and language summarization to deliver automated documentation of your visit to the doctor’s office. Notion is making inroads into uprooting Google Workspace or Microsoft Office, while Perplexity wants to reinvent the search engine. (Read more about Notion and Perplexity in our accompanying feature stories.)\nThe artificial intelligence sector has never been more competitive. Forbes received some 1,900 submissions this year, more than double last year’s count. Applicants do not pay a fee to be considered and are judged for their business promise and technical usage of AI through a quantitative algorithm and qualitative judging panels. Companies are encouraged to share data on diversity, and our list aims to promote a more equitable startup ecosystem. But disparities remain sharp in the industry. Only 12 companies have women cofounders, five of whom serve as CEO, the same count as last year. For more, see our full package of coverage, including a detailed explanation of the list methodology, videos and analyses on trends in AI.\nIn rare instances where the company did not disclose information, Forbes uses data provided by PitchBook and Crunchbase.\n_________________\nOperational Lead: Elisabeth Brier\nReporters: Rashi Shrivastava, Lauren Orsini and Leah Rosenbaum.\nData Partners: Konstantine Buhler (Sequoia), Rob Ward (Meritech) and Dan Knight (Meritech).\nDisclosure: The 2024 AI 50 includes companies that have taken investment from Sequoia, which helped create this list. Sequoia has publicly disclosed investments in Cresta, ElevenLabs, Glean, Harvey, Hugging Face, Kumo.AI, LangChain, Notion, OpenAI, Replicate and Sierra; Meritech is not an investor of any companies on the list.\nCLICK HERE FOR THE FULL METHODOLOGY.\nNew and Noteworthy\nAbridge\nHQ\n:\nPENNSYLVANIA\nCEO\n:\nSHIV RAO\nFUNDING\n:\n$212.5 MIL\nFUNDED\n:\n2018\nDr. Rao, a practicing cardiologist, founded Abridge to free clinicians from the time-sucking paperwork that’s required after they see patients: jotting down detailed notes for their medical records. Abridge records their conversations with patients and uses AI to summarize them. Ten thousand clinicians are already using it, and the startup is worth $850 million after raising more than $200 million in venture funding.\nView Profile\nHarvey\nHQ\n:\nCALIFORNIA\nCEO\n:\nWINSTON WEINBERG\nFUNDING\n:\n$106 MIL\nFUNDED\n:\n2022\nHarvey caters to the needs of more than 10,000 time-pressed lawyers, helping them research cases, draft and review contracts and find legal precedents. Roommates Weinberg and Gabriel Pereyra cofounded the startup in 2022 to offload legal drudgery, and their AI tech is already used by elite law firms like British barristers Allen & Overy and Macfarlanes. The startup has raised over $100 million in venture capital, $80 million of which it scooped up at a $715 million valuation in late 2023 from prominent tech investors Elad Gil, Kleiner Perkins, the OpenAI Startup Fund and Sequoia.\nView Profile\nMistral AI\nHQ\n:\nFRANCE\nCEO\n:\nARTHUR MENSCH\nFUNDING\n:\n$527.8 MIL\nFUNDED\n:\n2023\nWidely considered the European rival to OpenAI, Mistral develops mostly free-of-charge open-source AI models. The startup, less than a year old, is valued at $2 billion, per PitchBook, with more than $500 million in venture capital from blue-chip shops like Andreessen Horowitz and Lightspeed Venture Partners. Microsoft, Nvidia and Salesforce all have smaller stakes. Mistral differentiates itself by developing smaller models that are less compute-intensive. In February, it debuted its ChatGPT alternative, a chatbot called “Le Chat.”\nView Profile\nPika\nHQ\n:\nCALIFORNIA\nCEO\n:\nDEMI GUO\nFUNDING\n:\n$55 MIL\nFUNDED\n:\n2023\nWith a few clicks, anyone can create videos of scuba divers exploring underwater sea life or a tiger prowling through a lush Indian forest using Pika’s generative AI software. Founded by two Stanford Ph.D. students in April 2023, Pika has already been used to make 35 million videos on the back of $55 million in funding from notable angels like former GitHub CEO Nat Friedman and Quora cofounder and CEO Adam D’Angelo. The nascent startup, with a 13-person, mostly female team, is valued at $250 million.\nView Profile\nThe Full List\nJoin\n1,000+\nListees Making the Most of their Forbes Accolade.\nLearn About Benefits\nFILTER BY COUNTRY\nAll\nAustralia\nCanada\nFrance\nGermany\nNetherlands\nSweden\nUnited Kingdom\nUnited States\nNAME\nWHAT IT DOES\nFUNDING\nYEAR FOUNDED\nHEADQUARTERS\nAbridge\nMedical conversation documentation\n$213 M\n2018\nPittsburgh, Pennsylvania, United States\nAdept\nAI model developer\n$415 M\n2022\nSan Francisco, California, United States\nAnduril Industries\nDefense software and hardware\n$2.8 B\n2017\nCosta Mesa, California, United States\nAnthropic\nAI model developer\n$7.7 B\n2020\nSan Francisco, California, United States\nAnyscale\nAI app deployment software\n$259 M\n2019\nSan Francisco, California, United States\nAssemblyAI\nSpeech transcription tooling provider\n$115 M\n2017\nSan Francisco, California, United States\nBaseten\nAI app deployment software\n$60 M\n2019\nSan Francisco, California, United States\nCerebras Systems\nComputer chip maker\n$720 M\n2016\nSunnyvale, California, United States\nCharacter.AI\nConsumer chatbot app\n$193 M\n2021\nMenlo Park, California, United States\nCleanlab\nError detection for data\n$30 M\n2021\nSan Francisco, California, United States\nCodeium\nCoding autocompletion app\n$93 M\n2021\nMountain View, California, United States\nCohere\nAI model developer\n$445 M\n2019\nToronto, Ontario, Canada\nCradle\nProtein design for drug discovery\n$33 M\n2021\nAmsterdam, Netherlands\nCresta\nCall center agent assistance\n$152 M\n2017\nPalo Alto, California, United States\nDatabricks\nData storage and analytics\n$4 B\n2013\nSan Francisco, California, United States\nDeepL\nLanguage translation service\n$100 M\n2017\nCologne, Germany\nElevenLabs\nVoice generation software\n$101 M\n2022\nLondon, United Kingdom\nFigure AI\nAutonomous humanoid robots\n$754 M\n2022\nSunnyvale, California, United States\nGlean\nEnterprise search engine\n$360 M\n2019\nPalo Alto, California, United States\nHarvey\nAI models for law firms\n$106 M\n2022\nSan Francisco, California, United States\nHebbia\nEnterprise search engine\n$30 M\n2020\nNew York, New York, United States\nHugging Face\nLibrary for AI models and datasets\n$395 M\n2016\nNew York, New York, United States\nInsitro\nDrug discovery and development\n$643 M\n2018\nSan Francisco, California, United States\nKumo.AI\nData analytics software\n$37 M\n2021\nMountain View, California, United States\nLangChain\nAI app development tools\n$35 M\n2023\nSan Francisco, California, United States\nLeonardo.AI\nImage generation service\n$31 M\n2022\nSydney, Australia\nMidjourney\nImage generation service\n$0 M\n2021\nSan Francisco, California, United States\nMistral AI\nOpen-source AI model research\n$528 M\n2023\nParis, France\nNotion\nProductivity software\n$330 M\n2013\nSan Francisco, California, United States\nOpenAI\nAI model developer\n$11.3 B\n2015\nSan Francisco, California, United States\nOwkin\nDrug discovery and development\n$304 M\n2016\nNew York, New York, United States\nPerplexity\nGeneral purpose search app\n$102 M\n2022\nSan Francisco, California, United States\nPhotoroom\nPhoto editing app\n$64 M\n2019\nParis, France\nPika\nVideo generation service\n$55 M\n2023\nPalo Alto, California, United States\nPinecone\nDatabase software\n$138 M\n2019\nNew York, New York, United States\nReplicate\nAI app deployment software\n$60 M\n2019\nSan Francisco, California, United States\nRosebud AI\nVideo game design software\n$10 M\n2019\nSan Francisco, California, United States\nRunway\nImage and video editing software\n$237 M\n2018\nNew York, New York, United States\nSana\nEnterprise learning and search\n$82 M\n2016\nStockholm, Sweden\nScale AI\nData labeling and software\n$600 M\n2016\nSan Francisco, California, United States\nSierra\nCustomer service software\n$110 M\n2023\nSan Francisco, California, United States\nSynthesia\nAI avatar and video generator\n$157 M\n2017\nLondon, United Kingdom\nTogether AI\nAI model development tools\n$229 M\n2022\nSan Francisco, California, United States\nTome\nPresentation creation software\n$81 M\n2020\nSan Francisco, California, United States\nTractian\nIndustrial machine maintenance\n$65 M\n2019\nAtlanta, Georgia, United States\nUnstructured\nAI app development tools\n$65 M\n2022\nSacramento, California, United States\nVannevar Labs\nDefense intelligence software\n$87 M\n2019\nPalo Alto, California, United States\nWaabi\nAutonomous trucking technology\n$84 M\n2021\nToronto, Ontario, Canada\nWeaviate\nDatabase software\n$68 M\n2019\nAmsterdam, Netherlands\nWriter\nEnterprise generative AI software\n$126 M\n2020\nSan Francisco, California, United States\nInquire for List Data\nRequest license data and information spreadsheet from this Forbes Ranking for research, reference and other limited use options.\nRead More\nHow Forbes Compiled The 2024 AI 50 List\nBy Kenrick Cai\n$10 Billion Productivity Startup Notion Wants To Build Your AI Everything App\nBy Kenrick Cai\n‘Like Wikipedia And ChatGPT Had A Kid’: Inside The Buzzy AI Startup Coming For Google’s Lunch\nBy Rashi Shrivastava\nAI’s Most Promising Startups Are Getting Younger And Leaner\nBy Kenrick Cai\nHow AI 50 Companies Are Powering A New Tech Economy\nBy Konstantine Buhler\nMore Forbes Lists\nThe World's Billionaires List\nBlockchain 50\nThe Forbes CIO Next List", 'image_urls': [], 'title': 'Forbes 2024 AI 50 List - Top Artificial Intelligence Startups'}, {'url': 'https://www.forbes.com/sites/garydrenik/2025/02/26/how-ai-startups-are-evaluating-the-latest-model-advancements/', 'raw_content': 'How AI Startups Are Evaluating The Latest Model Advancements\nHow AI Startups Are Evaluating The Latest Model Advancements\nBy\nGary Drenik\nFollow\nSave Article\nComment\nLeadership\nLeadership Strategy\nHow AI Startups Are Evaluating The Latest Model Advancements\nBy\nGary Drenik\n, Contributor.\nGary Drenik is a writer covering AI, analytics and innovation.\nFollow Author\nFeb 26, 2025, 10:00am EST\nSave Article\nComment\nAI Tools\nAdobeStock_1234976134_Editorial_Use_Only\nDeepSeek’s R1 is shaking up the AI landscape. Launched on January 20, this advanced reasoning model claims performance on par with OpenAI’s o1 — at just 2% of the cost. Unlike other frontier models reliant on high-end chips and massive datasets, R1 is optimized for older hardware and leverages novel reinforcement learning techniques, allegedly slashing training costs to $6 million.\nBeyond efficiency, R1’s open-source MIT license makes it freely accessible, allowing companies to integrate or customize it freely. This raises a pivotal question: Will AI companies embrace DeepSeek, or will stalwarts like OpenAI and Anthropic remain the industry’s default choices?\nAccording to a recent\nProsper Insights & Analytics\nsurvey, 48% of U.S. executives and 38% of U.S. adults are already aware of DeepSeek. Such broad recognition less than a month after R1’s launch is remarkable, hinting that the big players may be facing a legitimate new competitor rather than a flashy — but short-lived — upstart.\nProsper- Heard of DeepSeek AI\nProsper Insights & Analytics\nMany of these executives, especially at cutting-edge AI companies, not only know about DeepSeek but are actively evaluating how and why they should adopt it. The affordable customization made possible with R1’s model is appealing for businesses seeking a competitive edge in customer-first AI markets, where advances in AI-powered services and customer support are key differentiators. “It\'s exciting to see an open-source model arrive that’s been trained for a fraction of the cost. It…bodes well for companies innovating AI at the application level,” said Bryan Murphy, CEO of AI translation solutions provider\nSmartling\n. “It\'s also a wakeup call to the hyperscalers that they\'re not moving fast enough." Case in point: to compete with DeepSeek, OpenAI accelerated its release of a new model, o3-mini, promising better performance at lower cost.\nMORE FOR YOU\nOscars 2025 Full Winners List (Live Updates)\nOscar Winners: ‘Anora’ Wins Best Picture While Adrien Brody And Mikey Madison Take Home Top Acting Honors\nIndia Beat New Zealand To Face Down Australia In Champions Trophy Semi\nFor emerging AI startups — which raised a record $97B last year — the financial benefit of using R1 to power their products may be particularly hard to ignore. “We launched support for R1 within a week, while we’ve held off supporting [OpenAI’s]\no1 because it’s so expensive we’d need to change how we charge our users,” noted Zach Lloyd, founder and CEO of\nWarp\n, which offers AI-powered software development tools.\nThen again, better margins are not the only driver of DeepSeek adoption. “Even more so than the reported training costs, what\'s so exciting about DeepSeek is the leap forward in reasoning and explainability,” according to Merrill Lutsky, CEO of\nGraphite\n— a platform for software engineers whose key differentiator is applying AI to software development and deployment roadblocks. For startups like Graphite, getting in early on powerful new technologies can help accelerate R&D and the launch of new products. If competitors fail to experiment and test the limits of new models like R1, those who do will be able to provide unique features and capabilities that set them apart.\nLutsky continued, “Seeing companies like Snowflake and Cursor add support for DeepSeek within a week reinforces our view that both enterprises and startups building the AI application layer will remain model-agnostic, so they can quickly add support for state-of-the-art models.”\nNotably, there were initial privacy concerns for companies wary of sending sensitive information to a China-based company. DeepSeek’s privacy policy notes that it collects and stores users’ information on servers in China, thus data like email addresses, phone numbers, passwords, and chat histories may be subject to government access by Chinese authorities. Security experts from Wiz Research set out to test DeepSeek’s security posture, and within minutes uncovered an exposed database “linked to DeepSeek, completely open and unauthenticated, exposing sensitive data.”\nIn any industry, but especially highly regulated ones like healthcare or financial services, protecting customer data must come before exploring any potential benefits of new technology. Given this, businesses were quick to take a strong user-first privacy stance when evaluating DeepSeek; executives across industries have been clear and proactive about the way they intend to use it. “To mitigate risk, startups can self-host the open-source model or use US-based hosting providers, though this may incur higher costs,” added Lloyd. This can be a game-changer — such as for healthcare companies striving to balance patient trust and privacy with innovation.\nSelf-hosting “completely changes how we think about ROI because we get superior model performance without compromising security or compliance by running [models] entirely locally, on systems we own and run,” said Ken Ko, CTO of\nFerrum Health\n, which helps health systems access the best clinical AI technologies.\nDeepSeek’s staying power hinges on its ability to balance radical innovation with global trust. R1’s supposed low training cost and open-source accessibility challenge the status quo, democratizing AI development for startups and enterprises alike. At the same time, data privacy concerns make its adoption a more complex calculation than simply supporting the latest model from a trusted alternative, like US-based Anthropic.\nThe AI industry now faces a pivotal choice: embrace R1’s cost efficiency and advanced capabilities to accelerate innovation or retreat to established players whose offerings have been tested for years against a broad range of industry use cases. DeepSeek’s rapid follow-up to R1 with the release of yet another model, Janus-Pro, signals its commitment to sustaining momentum. Ultimately, it remains to be seen whether its technical ingenuity will be enough to overtake big players who are already household names.\nCheck out\nmy\nwebsite\n.\nEditorial Standards\nForbes Accolades', 'image_urls': [], 'title': 'How AI Startups Are Evaluating The Latest Model Advancements'}, {'url': 'https://a16z.com/emerging-architectures-for-llm-applications/', 'raw_content': 'Emerging Architectures for LLM Applications | Andreessen Horowitz\nEmerging Architectures for LLM Applications\nMatt Bornstein\nand\nRajko Radovanovic\nshare\nCopy Link\nEmail\nX\nLinkedIn\nFacebook\nHacker News\nWhatsApp\nFlipboard\nReddit\nExplore more: AI + a16z\nTable of Contents\nTable of Contents\nPosted June 20, 2023\nLarge language models are a powerful new primitive for building software. But since they are so new—and behave so differently from normal computing resources—it’s not always obvious how to use them.\nIn this post, we’re sharing a reference architecture for the emerging LLM app stack. It shows the most common systems, tools, and design patterns we’ve seen used by AI startups and sophisticated tech companies. This stack is still very early and may change substantially as the underlying technology advances, but we hope it will be a useful reference for developers working with LLMs now.\nThis work is based on conversations with AI startup founders and engineers. We relied especially on input from: Ted Benson, Harrison Chase, Ben Firshman, Ali Ghodsi, Raza Habib, Andrej Karpathy, Greg Kogan, Jerry Liu, Moin Nadeem, Diego Oppenheimer, Shreya Rajpal, Ion Stoica, Dennis Xu, Matei Zaharia, and Jared Zoneraich. Thank you for your help!\nNote: A living and more comprehensive version of these components is available in our\nLLM App Stack repo\non GitHub.\nThe stack\nHere’s our current view of the LLM app stack (click to enlarge):\nAnd here’s a list of links to each project for quick reference:\nData pipelines\nEmbedding model\nVector database\nPlayground\nOrchestration\nAPIs/plugins\nLLM cache\nDatabricks\nOpenAI\nPinecone\nOpenAI\nLangchain\nSerp\nRedis\nAirflow\nCohere\nWeaviate\nnat.dev\nLlamaIndex\nWolfram\nSQLite\nUnstructured\nHugging Face\nChromaDB\nHumanloop\nChatGPT\nZapier\nGPTCache\npgvector\nLogging / LLMops\nValidation\nApp hosting\nLLM APIs (proprietary)\nLLM APIs (open)\nCloud providers\nOpinionated clouds\nWeights & Biases\nGuardrails\nVercel\nOpenAI\nHugging Face\nAWS\nDatabricks\nMLflow\nRebuff\nSteamship\nAnthropic\nReplicate\nGCP\nAnyscale\nPromptLayer\nMicrosoft Guidance\nStreamlit\nAzure\nMosaic\nHelicone\nLMQL\nModal\nCoreWeave\nModal\nRunPod\nThere are many different ways to build with LLMs, including training models from scratch, fine-tuning open-source models, or using hosted APIs. The stack we’re showing here is based on\nin-context learning\n, which is the design pattern we’ve seen the majority of developers start with (and is only possible now with foundation models).\nThe next section gives a brief explanation of this pattern; experienced LLM developers can skip this section.\nDesign pattern: In-context learning\nThe core idea of in-context learning is to use LLMs off the shelf (i.e., without any fine-tuning), then control their behavior through clever prompting and conditioning on private “contextual” data.\nFor example, say you’re building a chatbot to answer questions about a set of legal documents. Taking a naive approach, you could paste all the documents into a ChatGPT or GPT-4 prompt, then ask a question about them at the end. This may work for very small datasets, but it doesn’t scale. The biggest GPT-4 model can only process ~50 pages of input text, and performance (measured by inference time and accuracy) degrades badly as you approach this limit, called a context window.\nIn-context learning solves this problem with a clever trick: instead of sending all the documents with each LLM prompt, it sends only a handful of the most relevant documents. And the most relevant documents are determined with the help of . . . you guessed it . . . LLMs.\nAt a very high level, the workflow can be divided into three stages:\nData preprocessing / embedding:\nThis stage involves storing private data (legal documents, in our example) to be retrieved later. Typically, the documents are broken into chunks, passed through an embedding model, then stored in a specialized database called a vector database.\nPrompt construction / retrieval:\nWhen a user submits a query (a legal question, in this case), the application constructs a series of prompts to submit to the language model. A compiled prompt typically combines a prompt template hard-coded by the developer; examples of valid outputs called few-shot examples; any necessary information retrieved from external APIs; and a set of relevant documents retrieved from the vector database.\nPrompt execution / inference:\nOnce the prompts have been compiled, they are submitted to a pre-trained LLM for inference—including both proprietary model APIs and open-source or self-trained models. Some developers also add operational systems like logging, caching, and validation at this stage.\nThis looks like a lot of work, but it’s usually easier than the alternative: training or fine-tuning the LLM itself. You don’t need a specialized team of ML engineers to do in-context learning. You also don’t need to host your own infrastructure or buy an expensive dedicated instance from OpenAI. This pattern effectively reduces an AI problem to a data engineering problem that most startups and big companies already know how to solve. It also tends to outperform fine-tuning for relatively small datasets—since a specific piece of information needs to occur at least ~10 times in the training set before an LLM will remember it through fine-tuning—and can incorporate new data in near real time.\nOne of the biggest questions around in-context learning is: What happens if we just change the underlying model to increase the context window? This is indeed possible, and it is an active area of research (e.g., see the\nHyena paper\nor this\nrecent post\n). But this comes with a number of tradeoffs—primarily that cost and time of inference scale quadratically with the length of the prompt. Today, even linear scaling (the best theoretical outcome) would be cost-prohibitive for many applications. A single GPT-4 query over 10,000 pages would cost hundreds of dollars at current API rates. So, we don’t expect wholesale changes to the stack based on expanded context windows, but we’ll comment on this more in the body of the post.\nIf you’d like to go deeper on in-context learning, there are a number of great resources in the\nAI canon\n(especially the “Practical guides to building with LLMs” section). In the remainder of this post, we’ll walk through the reference stack, using the workflow above as a guide.\nContextual data\nfor LLM apps includes text documents, PDFs, and even structured formats like CSV or SQL tables. Data-loading and transformation solutions for this data vary widely across developers we spoke with. Most use traditional ETL tools like Databricks or Airflow. Some also use document loaders built into orchestration frameworks like LangChain (powered by Unstructured) and LlamaIndex (powered by Llama Hub). We believe this piece of the stack is relatively underdeveloped, though, and there’s an opportunity for data-replication solutions purpose-built for LLM apps.\nFor\nembeddings\n, most developers use the OpenAI API, specifically with the\ntext-embedding-ada-002\nmodel\n. It’s easy to use (especially if you’re already already using other OpenAI APIs), gives reasonably good results, and is becoming increasingly cheap. Some larger enterprises are also exploring Cohere, which focuses their product efforts more narrowly on embeddings and has better performance in certain scenarios. For developers who prefer open-source, the Sentence Transformers library from Hugging Face is a standard. It’s also possible to\ncreate different types of embeddings\ntailored to different use cases; this is a niche practice today but a promising area of research.\nThe most important piece of the preprocessing pipeline, from a systems standpoint, is the\nvector database\n. It’s responsible for efficiently storing, comparing, and retrieving up to billions of embeddings (i.e., vectors). The most common choice we’ve seen in the market is Pinecone. It’s the default because it’s fully cloud-hosted—so it’s easy to get started with—and has many of the features larger enterprises need in production (e.g., good performance at scale, SSO, and uptime SLAs).\nThere’s a huge range of vector databases available, though. Notably:\nOpen source systems like Weaviate, Vespa, and Qdrant:\nThey generally give excellent single-node performance and can be tailored for specific applications, so they are popular with experienced AI teams who prefer to build bespoke platforms.\nLocal vector management libraries like Chroma and Faiss:\nThey have great developer experience and are easy to spin up for small apps and dev experiments. They don’t necessarily substitute for a full database at scale.\nOLTP extensions like pgvector:\nFor devs who see every database-shaped hole and try to insert Postgres—or enterprises who buy most of their data infrastructure from a single cloud provider—this is a good solution for vector support. It’s not clear, in the long run, if it makes sense to tightly couple vector and scalar workloads.\nLooking ahead, most of the open source vector database companies are developing cloud offerings. Our research suggests achieving strong performance in the cloud, across a broad design space of possible use cases, is a very hard problem. Therefore, the option set may not change massively in the near term, but it likely will change in the long term. The key question is whether vector databases will resemble their OLTP and OLAP counterparts, consolidating around one or two popular systems.\nAnother open question is how embeddings and vector databases will evolve as the usable context window grows for most models. It’s tempting to say embeddings will become less relevant, because contextual data can just be dropped into the prompt directly. However, feedback from experts on this topic suggests the opposite—that the embedding pipeline may become\nmore\nimportant over time. Large context windows are a powerful tool, but they also entail significant computational cost. So making efficient use of them becomes a priority. We may start to see different types of embedding models become popular, trained directly for model relevancy, and vector databases designed to enable and take advantage of this.\nStrategies for prompting LLMs and incorporating contextual data are becoming increasingly complex—and increasingly important as a source of product differentiation. Most developers start new projects by experimenting with simple prompts, consisting of direct instructions (zero-shot prompting) or possibly some example outputs (few-shot prompting). These prompts often give good results but fall short of accuracy levels required for production deployments.\nThe next level of prompting jiu jitsu is designed to ground model responses in some source of truth and provide external context the model wasn’t trained on. The\nPrompt Engineering Guide\ncatalogs no fewer than 12 (!) more advanced prompting strategies, including chain-of-thought, self-consistency, generated knowledge, tree of thoughts, directional stimulus, and many others. These strategies can also be used in conjunction to support different LLM use cases like document question answering, chatbots, etc.\nThis is where\norchestration\nframeworks like LangChain and LlamaIndex shine. They abstract away many of the details of prompt chaining; interfacing with external APIs (including determining when an API call is needed); retrieving contextual data from vector databases; and maintaining memory across multiple LLM calls. They also provide templates for many of the common applications mentioned above. Their output is a prompt, or series of prompts, to submit to a language model. These frameworks are widely used among hobbyists and startups looking to get an app off the ground, with LangChain the leader.\nLangChain is still a relatively new project (currently on version 0.0.201), but we’re already starting to see apps built with it moving into production. Some developers, especially early adopters of LLMs, prefer to switch to raw Python in production to eliminate an added dependency. But we expect this DIY approach to decline over time for most use cases, in a similar way to the traditional web app stack.\nSharp-eyed readers will notice a seemingly weird entry in the orchestration box: ChatGPT. In its normal incarnation, ChatGPT is an app, not a developer tool. But it can also be accessed as an API. And, if you squint, it performs some of the same functions as other orchestration frameworks, such as: abstracting away the need for bespoke prompts; maintaining state; and retrieving contextual data via plugins, APIs, or\nother sources\n. While not a direct competitor to the other tools listed here, ChatGPT can be considered a substitute solution, and it may eventually become a viable, simple alternative to prompt construction.\nToday, OpenAI is the leader among\nlanguage models\n. Nearly every developer we spoke with starts new LLM apps using the OpenAI API, usually with the\ngpt-4\nor\ngpt-4-32k\nmodel. This gives a best-case scenario for app performance and is easy to use, in that it operates on a wide range of input domains and usually requires no fine-tuning or self-hosting.\nWhen projects go into production and start to scale, a broader set of options come into play. Some of the common ones we heard include:\nSwitching to\ngpt-3.5-turbo\n:\nIt’s ~\n50x cheaper\nand significantly faster than GPT-4. Many apps don’t need GPT-4-level accuracy, but do require low latency inference and cost effective support for free users.\nExperimenting with other proprietary vendors\n(especially Anthropic’s Claude models)\n:\nClaude offers fast inference, GPT-3.5-level accuracy, more customization options for large customers, and up to a 100k context window (though we’ve found accuracy degrades with the length of input).\nTriaging some requests to open source models:\nThis can be especially effective in high-volume B2C use cases like search or chat, where there’s wide variance in query complexity and a need to serve free users cheaply.\nThis usually makes the most sense in conjunction with fine-tuning open source base models. We don’t go deep on that tooling stack in this article, but platforms like Databricks, Anyscale, Mosaic, Modal, and RunPod are used by a growing number of engineering teams.\nA variety of inference options are available for open source models, including simple API interfaces from Hugging Face and Replicate; raw compute resources from the major cloud providers; and more opinionated cloud offerings like those listed above.\nOpen-source models\ntrail proprietary offerings right now, but the gap is starting to close. The LLaMa models from Meta set a new bar for open source accuracy and kicked off a flurry of variants. Since LLaMa was licensed for research use only, a number of new providers have stepped in to train alternative base models (e.g., Together, Mosaic, Falcon, Mistral). Meta is also\ndebating\na truly open source release of LLaMa 2.\nWhen (not if) open source LLMs reach accuracy levels comparable to GPT-3.5, we expect to see a Stable Diffusion-like moment for text—including massive experimentation, sharing, and productionizing of fine-tuned models. Hosting companies like Replicate are already adding tooling to make these models easier for software developers to consume. There’s a growing belief among developers that smaller, fine-tuned models can reach state-of-the-art accuracy in narrow use cases.\nMost developers we spoke with haven’t gone deep on\noperational tooling\nfor LLMs yet. Caching is relatively common—usually based on Redis—because it improves application response times and cost. Tools like Weights & Biases and MLflow (ported from traditional machine learning) or PromptLayer and Helicone (purpose-built for LLMs) are also fairly widely used. They can log, track, and evaluate LLM outputs, usually for the purpose of improving prompt construction, tuning pipelines, or selecting models. There are also a number of new tools being developed to validate LLM outputs (e.g., Guardrails) or detect prompt injection attacks (e.g., Rebuff). Most of these operational tools encourage use of their own Python clients to make LLM calls, so it will be interesting to see how these solutions coexist over time.\nFinally, the static portions of LLM apps (i.e. everything other than the model) also need to be\nhosted\nsomewhere. The most common solutions we’ve seen so far are standard options like Vercel or the major cloud providers. However, two new categories are emerging. Startups like Steamship provide end-to-end hosting for LLM apps, including orchestration (LangChain), multi-tenant data contexts, async tasks, vector storage, and key management. And companies like Anyscale and Modal allow developers to host models and Python code in one place.\nWhat about agents?\nThe most important components missing from this reference architecture are\nAI agent frameworks\n.\nAutoGPT\n, described as “\nan experimental open-source attempt to make GPT-4 fully autonomous\n,” was the\nfastest-growing Github repo in history\nthis spring, and practically every AI project or startup out there today includes agents in some form.\nMost developers we speak with are incredibly excited about the potential of agents. The in-context learning pattern we describe in this post is effective at solving hallucination and data-freshness problems, in order to better support content-generation tasks. Agents, on the other hand, give AI apps a fundamentally new set of capabilities: to solve complex problems, to act on the outside world, and to learn from experience post-deployment. They do this through a combination of advanced reasoning/planning, tool usage, and memory / recursion / self-reflection.\nSo, agents have the potential to become a central piece of the LLM app architecture (or even take over the whole stack, if you believe in recursive self-improvement). And existing frameworks like LangChain have incorporated some agent concepts already. There’s only one problem: agents don’t really work yet. Most agent frameworks today are in the proof-of-concept phase—capable of incredible demos but not yet reliable, reproducible task-completion. We’re keeping an eye on how they develop in the near future.\nLooking ahead\nPre-trained AI models represent the most important architectural change in software since the internet. They make it possible for individual developers to build incredible AI apps, in a matter of days, that surpass supervised machine learning projects that took big teams months to build.\nThe tools and patterns we’ve laid out here are likely the starting point, not the end state, for integrating LLMs. We’ll update this as major changes take place (e.g., a shift toward model training) and release new reference architectures where it makes sense. Please reach out if you have any feedback or suggestions.\nStay up to date on the latest from a16z Infra team\nSign up for our a16z newsletter to get analysis and news covering the latest trends reshaping AI and infrastructure.\nThanks for signing up.\nCheck your inbox for a welcome note.\nMANAGE MY SUBSCRIPTIONS\nBy clicking the Subscribe button, you agree to the\nPrivacy Policy\n.\nContributors\nMatt Bornstein\nis a partner at Andreessen Horowitz focused on AI, data systems, and infrastructure.\nFollow\nX\nLinkedin\nRajko Radovanovic\nis an investing partner on the infrastructure team at Andreessen Horowitz.\nFollow\nX\nLinkedin\nMore From These Contributors\nBuilding Developers Tools, From Docker to Diffusion Models\nBen Firshman, Matt Bornstein, and Derrick Harris\nInvesting in Cursor\nMatt Bornstein, Marco Mascorro, Rajko Radovanovic, and Martin Casado\nInvesting in Black Forest Labs\nAnjney Midha, Marco Mascorro, Rajko Radovanovic, and Justine Moore\nOpen Models and Maturation: Assessing the Generative AI Market\nGuido Appenzeller, Matt Bornstein, and Derrick Harris\nScoping the Enterprise LLM Market\nNaveen Rao, Matt Bornstein, and Derrick Harris\nThe views expressed here are those of the individual AH Capital Management, L.L.C. (“a16z”) personnel quoted and are not the views of a16z or its affiliates. Certain information contained in here has been obtained from third-party sources, including from portfolio companies of funds managed by a16z. While taken from sources believed to be reliable, a16z has not independently verified such information and makes no representations about the enduring accuracy of the information or its appropriateness for a given situation. In addition, this content may include third-party advertisements; a16z has not reviewed such advertisements and does not endorse any advertising content contained therein.\nThis content is provided for informational purposes only, and should not be relied upon as legal, business, investment, or tax advice. You should consult your own advisers as to those matters. References to any securities or digital assets are for illustrative purposes only, and do not constitute an investment recommendation or offer to provide investment advisory services. Furthermore, this content is not directed at nor intended for use by any investors or prospective investors, and may not under any circumstances be relied upon when making a decision to invest in any fund managed by a16z. (An offering to invest in an a16z fund will be made only by the private placement memorandum, subscription agreement, and other relevant documentation of any such fund and should be read in their entirety.) Any investments or portfolio companies mentioned, referred to, or described are not representative of all investments in vehicles managed by a16z, and there can be no assurance that the investments will be profitable or that other investments made in the future will have similar characteristics or results. A list of investments made by funds managed by Andreessen Horowitz (excluding investments for which the issuer has not provided permission for a16z to disclose publicly as well as unannounced investments in publicly traded digital assets) is available at\nhttps://a16z.com/investments/\n.\nCharts and graphs provided within are for informational purposes solely and should not be relied upon when making any investment decision. Past performance is not indicative of future results. The content speaks only as of the date indicated. Any projections, estimates, forecasts, targets, prospects, and/or opinions expressed in these materials are subject to change without notice and may differ or be contrary to opinions expressed by others. Please see\nhttps://a16z.com/disclosures\nfor additional important information.\nStay up to date on the latest from a16z Infra team\nSign up for our a16z newsletter to get analysis and news covering the latest trends reshaping AI and infrastructure.\nThanks for signing up.\nCheck your inbox for a welcome note.\nMANAGE MY SUBSCRIPTIONS\nBy clicking the Subscribe button, you agree to the\nPrivacy Policy\n.\nRECOMMENDED FOR YOU\nAI, Crypto, and Building the Next Internet with a16z’s Chris Dixon\nDavid George\nand\nChris Dixon\nRead More\nUnbundling the BPO: How AI Will Disrupt Outsourced Work\nKimberly Tan\nRead More\nFrom Prompt to Product: The Rise of AI-Powered Web App Builders\nJustine Moore\n,\nYoko Li\n,\nGabriel Vasquez\n,\nMarco Mascorro\n, and\nBryan Kim\nRead More\nAI and the Promise of Hardware Iteration at Software Speed\nMillen Anand\nRead More\nSetting the Agenda for Global AI Leadership: Assessing the Roles of Congress and the States\nMatt Perault\nRead More\ngo to top\nPower User Menu\nHome\nH\nBy navigating this website you agree to our\ncookie\xa0policy\n.\nAccept\nDecline', 'image_urls': [{'url': 'https://a16z.com/wp-content/uploads/2023/06/2657-Emerging-LLM-App-Stack-R2-1-of-4-2-1024x717.png', 'score': 1}, {'url': 'https://a16z.com/wp-content/uploads/2023/06/2657-Emerging-LLM-App-Stack-R2-2-of-4-2-1024x717.png', 'score': 1}, {'url': 'https://a16z.com/wp-content/uploads/2023/06/2657-Emerging-LLM-App-Stack-R2-3-of-4-2-1024x717.png', 'score': 1}, {'url': 'https://a16z.com/wp-content/uploads/2023/06/2657-Emerging-LLM-App-Stack-R2-4-of-4-2-1024x717.png', 'score': 1}], 'title': 'Emerging Architectures for LLM Applications | Andreessen Horowitz'}, {'url': 'https://www.ai-supremacy.com/p/emerging-architectures-in-ai', 'raw_content': 'Emerging Architectures in AI - by Michael Spencer\nAI Supremacy\nSubscribe\nSign in\nShare this post\nAI Supremacy\nEmerging Architectures in AI\nCopy link\nFacebook\nEmail\nNotes\nMore\nEmerging Architectures in AI\nLiquid AI, Inference, Memory, Application layers updates, semiconductor potential. Super Datacenters.\nMichael Spencer\nDec 16, 2024\n∙ Paid\n65\nShare this post\nAI Supremacy\nEmerging Architectures in AI\nCopy link\nFacebook\nEmail\nNotes\nMore\n12\n14\nShare\nLiquid AI founders Mathias Lechner, Alexander Amini, Daniela Rus and Ramin Hasani. Source: Katherine Taylor.\nShare\nAI Supremacy is a reader supported publication, sharing our work helps us grow and is very much appreciated.\nThere’s something to be said for finding emergent architectures or new ways of doing things. Take Groq’s\nLanguage Processing Unit\n(\nLPU\n) a specialized\nAI accelerator designed\nto optimize the performance of artificial intelligence workloads, particularly in inference tasks. Or Sandbox AQ’s\nLarge Quantitative Models\n, LQMs.\nOr take Sakana AI’s\nNeural Attention Memory Models\n(NAMMs) that they say are a new kind of\nneural memory system\nfor Transformers that not only boost their performance and efficiency but are also transferable to other foundation models, without any additional training.\nWhen we think of what’s ahead, Ilya Sutskever\ngave us a nice summary\nrecently at NeurIPS, giving us additional context of the\nrecent history of AI\n. If he confirmed that LLMs scaling has plateaued in terms of training data, this bottleneck allows for other innovations to take place. Deep learning never rests, even in pushing the boundaries of things like\ndrug development\nand the future of biotechnology.\nBroadcom believes hyperscalers\nwill deploy 1,000,000 XPU clusters\nacross a single fabric as soon as 2027, which is 10x that of which xAI has today in terms of datacenter AI compute. In just a few short years, Scaling laws with be powered by a greater focus on inference, memory,\nAgentic AI\n, and on the application layer with tremendously more capable GPUs and AI infrastructure. Broadcom itself is working with the likes of ByteDance, Apple and OpenAI on custom AI chips.\nIn the decade ahead we are somewhat likely to find new kinds of emergent architectures that expand what we are able to do with LLMs or perhaps will be more efficient and open up new avenues, even as\nsmall language models\n, and\nworld models\ncontinue to expand our horizons.\nAI pioneer Fei-Fei Li’s World Labs has raised $230 million to build “\nlarge world models\n” (LWMs) with a lot of experimentation at places like Google on world simulators. Google recently\nannounced Genie 2\n, a foundation world model capable of generating an endless variety of action-controllable, playable 3D environments for training and evaluating embodied agents.\nHeading into 2025 we don’t know exactly what to expect. We do know that capex is only going to increase and national competition could accelerate innovation.\nAccording\nto one estimate, the global AI market reached $196.63 billion in 2023 and could be worth $1.81 trillion by 2030. In Short, the AI market is expected to\ngrow at a CAGR of 36.6% from 2024 to 2030\nreaching the remarkable figure of 1,811.75 million USD.\nRecently\nOmar Sanseviero\nof Hugging Face has released a book worth checking out if you dabble with LLMs, called\nHands-On Generative AI with Transformers and Diffusion Models\n. It’s available at\nO’Reilly\nand\nAmazon\n. I’m not an affiliate, only an enthusiast. There are so many good books coming out around LLMs, those by\nSebastian Raschka, PhD\nin my view\nare great\n.\nI want to talk especially about AMD’s best on Liquid AI and\nAyar Labs\nand what their architectures might mean for the future.\nUpgrades at the Application Layer\nKeep reading with a 7-day free trial\nSubscribe to\nAI Supremacy\nto keep reading this post and get 7 days of free access to the full post archives.\nStart trial\nAlready a paid subscriber?\nSign in\nPrevious\nNext\nShare\nCopy link\nFacebook\nEmail\nNotes\nMore\nThis site requires JavaScript to run correctly. Please\nturn on JavaScript\nor unblock scripts', 'image_urls': [{'url': 'https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37392efd-a75c-466f-96ac-539b71e61a7a_2000x1334.webp', 'score': 2}], 'title': 'Emerging Architectures in AI  - by Michael Spencer'}, {'url': 'https://techcrunch.com/2025/02/26/inception-emerges-from-stealth-with-a-new-type-of-ai-model/', 'raw_content': "Inception emerges from stealth with a new type of AI model | TechCrunch\nInception emerges from stealth with a new type of AI model | TechCrunch\nImage Credits:\nInception\nAI\nInception emerges from stealth with a new type of AI model\nMarina Temkin\n11:00 AM PST · February 26, 2025\nInception\n, a new Palo Alto-based company started by Stanford computer science professor Stefano Ermon, claims to have developed a novel AI model based on “diffusion” technology. Inception calls it a diffusion-based large language model, or a “DLM” for short.\nThe generative AI models receiving the most attention now can be broadly divided into two types: large language models (LLMs) and diffusion models. LLMs are used for text generation. Meanwhile, diffusion models, which power AI systems like\nMidjourney\nand OpenAI’s\nSora\n, are mainly used to create images, video, and audio.\nInception’s model offers the capabilities of traditional LLMs, including code generation and question-answering, but with significantly faster performance and reduced computing costs, according to the company.\nErmon told TechCrunch that he has been studying how to apply\ndiffusion models\nto text for a long time in his Stanford lab. His research was based on the idea that traditional LLMs are relatively slow compared to diffusion technology.\nWith LLMs, “you cannot generate the second word until you’ve generated the first one, and you cannot generate the third one until you generate the first two,” Ermon said.\nErmon was looking for a way to apply a diffusion approach to text because, unlike with LLMs, which work sequentially, diffusion models start with a rough estimate of data they’re generating (e.g. ,a picture), and then bring the data into focus all at once.\nErmon hypothesized generating and modifying large blocks of text in parallel was possible with diffusion models.\xa0After years of trying, Ermon and a student of his achieved a major breakthrough, which they detailed in a\nresearch paper\npublished last year.\nRecognizing the advancement’s potential, Ermon founded Inception last summer, tapping two former students, UCLA professor Aditya Grover and Cornell professor Volodymyr Kuleshov, to co-lead the company.\nWhile Ermon declined to discuss Inception’s funding, TechCrunch understands that the Mayfield Fund has invested.\nInception has already secured several customers, including unnamed Fortune 100 companies, by addressing their critical need for reduced AI latency and increased speed, Emron said.\n“What we found is that our models can leverage the GPUs much more efficiently,” Ermon said, referring to the computer chips commonly used to run models in production. “I think this is a big deal. This is going to change the way people build language models.”\nInception offers an API as well as on-premises and edge device deployment options, support for model fine-tuning, and a suite of out-of-the-box DLMs for various use cases. The company claims its DLMs can run up to 10x faster than traditional LLMs while costing 10x less.\n“Our ‘small’ coding model is as good as [OpenAI’s]\nGPT-4o mini\nwhile more than 10 times as fast,” a company spokesperson told TechCrunch. “Our ‘mini’ model outperforms small open-source models like [Meta’s]\nLlama 3.1 8B\nand achieves more than 1,000 tokens per second.”\n“Tokens” is industry parlance for bits of raw data. One thousand tokens per second is\nan impressive speed indeed\n, assuming Inception’s claims hold up.\nTopics\nAI\n,\ndiffusion\n,\ndlms\n,\nFunding\n,\nFundraising\n,\ninception\n,\nStartups\nMarina Temkin\nReporter, Venture\nMarina Temkin is a venture capital and startups reporter at TechCrunch. Prior to joining TechCrunch, she wrote about VC for PitchBook and Venture Capital Journal. Earlier in her career, Marina was a financial analyst and earned a CFA charterholder designation.\nView Bio\nMost Popular\nSignal is the number-one downloaded app in the Netherlands. But why?\nPaul Sawers\nTrump calls for creation of a ‘crypto strategic reserve’\nAnthony Ha\nMark Cuban offers to fund government tech unit that was cut in the middle of the night\nConnie Loizos\nBen Horowitz donates Cybertruck fleet to the Las Vegas police\nSean O'Kane\nHow to get rid of the new Apple Mail redesign\nAmanda Silberling\nSergey Brin says RTO is key to Google winning the AGI race\nMaxwell Zeff\nBluesky-based Instagram alternative Flashes launches publicly\nSarah Perez\nNewsletters\nSee More\nSubscribe for the industry’s biggest tech news\nTechCrunch Daily News\nEvery weekday and Sunday, you can get the best of TechCrunch’s coverage.\nTechCrunch AI\nTechCrunch's AI experts cover the latest news in the fast-moving field.\nTechCrunch Space\nEvery Monday, gets you up to speed on the latest advances in aerospace.\nStartups Weekly\nStartups are the core of TechCrunch, so get our best coverage delivered weekly.\nNo newsletters selected.\nSubscribe\nBy submitting your email, you agree to our\nTerms\nand\nPrivacy Notice\n.\nRelated\nStartups\nOpenAI’s startup empire: The companies backed by its venture fund\nMarina Temkin\n2 days ago\nAI\nWhat is Mistral AI? Everything to know about the OpenAI competitor\nAnna Heim\n2 days ago\nAI\nSymbyAI raises $2.1M seed to make science research easier\nDominic-Madori Davis\n2 days ago\nLatest in AI\nSee More\nIn Brief\nApple might not release a truly ‘modernized’ Siri until 2027\nAnthony Ha\n9 hours ago\nAI\nFlora is building an AI-powered ‘infinite canvas’ for creative professionals\nAnthony Ha\n9 hours ago\nTC Sessions: AI\nLast chance! Last 24 hours to save up to $325 on TechCrunch Sessions: AI\nTechCrunch Events\n17 hours ago", 'image_urls': [{'url': 'https://techcrunch.com/wp-content/uploads/2025/02/founders_together.jpg?w=1024', 'score': 1}], 'title': 'Inception emerges from stealth with a new type of AI model | TechCrunch'}, {'url': 'https://cloud.google.com/transform/future-of-ai-for-startups-23-industry-leaders-survey', 'raw_content': 'What\'s next in AI for startups, from 23 industry leaders | Google Cloud Blog\nStartups\nThe future of AI: 23 industry leaders on what\'s next in\nAI for startups\nFebruary 26, 2025\nDarren Mowry\nManaging Director, Global Startups\nJoin us at Google Cloud Next\nApril 9-11 in Las Vegas\nRegister\n“AI is transforming every organization around the world and represents an unprecedented opportunity to solve complex problems, drive growth, create efficiencies, and open up new business opportunities. This is particularly true for startups, who are moving very quickly to address new market opportunities with AI”\n- Thomas Kurian, CEO of Google Cloud.\nStartups are leading the generative AI charge by experimenting with new applications across industries, pushing the boundaries of what\'s possible, and advancing the technology\'s potential. They are the engine of gen AI innovation in a rapidly evolving landscape.\nTo gain a deeper understanding of just where gen AI might be headed — and the business world along with it — we\'ve gathered perspectives from 23 industry leaders and investors on AI\'s trajectory and implications for startups in 2025 and beyond. We’re publishing our findings today in Google Cloud’s latest report, the "\nFuture of AI: Perspectives for Startups 2025.\n"\nThe evolving role of AI agents\nAmong the trends discussed,\nAI agents\nwere the leading topic of conversation. The growing innovation of AI leaders with agents comes as no surprise, but their collective vision of how these agentic systems will evolve reveals an intriguing perspective on the increasingly sophisticated interactions we’ll soon encounter and their business implications.\nNew perspectives on AI\nWant to learn more from our nearly two-dozen experts on where they see AI heading for startups? Make the most of their frontline experience building, investing in, and operating some of the most exciting AI companies on the horizon. Download the full report to learn more.\nRead it now.\nDavid Thacker,\nVP of product at Google DeepMind, points out that “\nGemini\ncan also natively use tools like Google Search to access real-time information, and\nDeepMind\'s Project Mariner\nhas demonstrated that agents built with the Gemini model can complete tasks using a web browser. Conversational experiences can now be built with the\nGemini Multimodal Live API,\nwhich accepts audio and video streaming input. The combination of these capabilities enables a new class of agentic experiences and we’re excited to see what startups build with Gemini in 2025.”\nThe opportunities seem quite expansive. For example,\nMatthieu Rouif,\nco-founder and CEO at Photoroom, emphasizes AI becoming increasingly adept at recognizing and responding to human emotions; this could enable AI systems to tailor content and experiences to individual emotional responses in ways that create more meaningful connections.\nJia Li\n, co-founder, president, and chief AI officer at LiveX AI, sees a similar evolution enabling AI agents to move beyond simple task completion to truly understand customer intent and emotional states, offering personalized guidance that feels more human than mechanical.\n“To truly leverage agentic systems," says\nHarrison Chase,\nCEO and co-founder of LangChain, "I want them to scale beyond just what I can ask them to do — to be ‘ambient agents,’ running in the background, always on, monitoring streams of events, and alerting me only when something interesting happens or when they need my help.” Such intelligence and deep personalization could transform customer experience and business relationships, marking a significant evolution from today\'s task-oriented AI to tomorrow\'s empathetic digital companions.\nRethinking AI infrastructure\nYet for all the amazing leaps AI is offering, almost none of it would be possible without the right infrastructure, which is another major focus topic.\n"Tight synchronization and massive compute requirements push infrastructure to never-seen-before levels of compute density and capability,” said\nAmin Vahdat,\nVP & GM for Systems and Cloud AI at Google Cloud.\nThe future infrastructure landscape will likely be characterized by modular architectures that combine smaller, specialized models across different data modalities, supported by sophisticated orchestration and observability layers.\n“Integrations and infrastructure for observable workflow management will become even more critical parts of the AI stack,"\nMayada Gonimah\n, CTO and co-founder at Thread AI, said.\n"Companies will need interfaces that let them insert AI in their existing workflows and test them in parallel to existing processes. I think being more intentional around where you embed AI and having the tooling around observability is going to be key moving forward as we build these production-worthy AI-native workflows.”\nInfrastructure efficiency will become a critical competitive differentiator, with organizations that achieve twice the efficiency gaining significant market advantages.\nArvind Jain,\nCEO of Glean, emphasizes the importance of designing your infrastructure to be more agnostic to model and tooling advancements. Predict what’s coming and enable plug-and-play where feasible to take advantage of updates without massive overhauls or disruptions.\nCloud providers will continue to play a central role, but successful organizations will build flexible systems that can seamlessly integrate new models and technologies. For a deep dive around into impactful trends like multimodal AI, customer experience, enterprise search, and more technical advancements,\ncheck out the full report\n.\nPriorities for investors in AI startups in 2025\nThe AI investors in the report are zeroing in on startups that deliver concrete solutions to real-world challenges, moving beyond the initial AI hype.\nSalim Teja\n, a partner at Radical Ventures, is focused on startups that use AI to address real problems such as improving health, fighting diseases, combating climate change, and addressing the affordable housing crisis through robotics in construction.\nHaving data alone isn\'t enough — investors want to see strategic use of high-quality, secure data that enhances AI performance in specific applications. Venture capitalists are particularly drawn to solutions that boost productivity and transform business operations, especially in developer tools.\nProducts need to be stickier to create lasting value, which means being both indispensable and deeply integrated into the user’s workflow.\nCrystal Huang, general partner at GV\nTweet this quote\nThe winning formula? A clear competitive edge, path to profitability, and deep integration into user workflows. According to\nCrystal Huang\n, a general partner at GV, “If your product is easy to implement, it’s just as easy to uninstall. Products need to be stickier to create lasting value, which means being both indispensable and deeply integrated into the user’s workflow.”\nLeapfrog the competition\nIn today\'s competitive AI landscape, building a defensible market position requires a sophisticated strategy that goes beyond simply implementing the latest models.\nYoav Shoham\n, co-founder of AI21 Labs, emphasizes the importance of "Product-Algo Fit" - understanding and leveraging current AI capabilities rather than banking on future potential. Rather than waiting for perfect models, organizations must invest continuously in evolution and adaptation, integrating AI solutions that solve real business problems and deliver measurable returns.\nDavid Friedberg,\nCEO of Ohalo Genetics, put it this way: “If you\'re just an LLM wrapper, it\'s going to be hard to build a sustainable business — you\'re likely going to get commoditized away. Businesses need an engine of value creation that persists with an initial advantaged offering with continuous improvements. This will typically come from proprietary data generation, which is used to continuously improve model performance, or network effects that lock-in access to data or customers.”\nLooking ahead\nThe breakneck pace of change being driven by generative AI means that startups are facing unprecedented challenges. At Google Cloud, we’re collaborating with researchers, founders, startups, investors, enterprises, partners, and public sector agencies to think critically about how our responsible AI solutions can meet the needs of employees, customers, patients, and citizens.\nThis includes providing world-class infrastructure and full-stack capabilities at the forefront of innovation, engaging deeply with inventors on data, agents, and applications to help bring new outcomes to life, and partnering with enterprises to evaluate how AI advances can modernize experiences both inside and outside organizations.\nOur hope is that the\nFuture of AI: Perspectives for Startups 2025\nreport will shed more light on one of the fastest-moving technologies our industry has ever seen — and in particular, provide exciting guidance to founders who are imagining the next wave of innovative AI startups.\nNo matter where you are with AI adoption, we’re here to help:\nBook\nyour generative AI consultation today, get up to $350,000 in cloud credits with the\nGoogle for Startups Cloud Program\n, or\ncontact\nour Startup sales team.\nPosted in\nStartups\nRelated articles\nStartups\nA gift of perspective: Founders share their defining moments\nBy Farris Pine • 2-minute read', 'image_urls': [], 'title': "What's next in AI for startups, from 23 industry leaders | Google Cloud Blog"}, {'url': 'https://enterpriseleague.com/blog/architecture-startups/', 'raw_content': '17 architecture startups to keep an eye on in 2025\nTop Startups\n17 architecture startups to keep an eye on in 2025\nFebruary 19, 2025\nThis centuries old industry thats been at the forefront of implementing modern tech in order to come up with innovative solutions. From leveraging AI and generative design to optimize and automate building design, to connecting clients directly with architects through digital platforms, architecture startups are making the design process more accessible, sustainable, and human-centric.\nTop arcitecture startups\nComplete list of the most arcitecture startups that are worth knowing:\nBrixel\nFounded in 2016, Brixel is a tech startup that builds intelligent spaces by integrating robotics, AI, and interactive design. Their systems can transform buildings for a variety of uses. The company uses state-of-the-art robotic frames paired with smart software to construct customizable structures. These reconfigurable building blocks can assemble, disassemble and rearrange on demand, altering floor plans rapidly.\nArchitects can create pop-up spaces like stages, kiosks or office spaces swiftly. The adaptable infrastructure also enables warehouses to shift shelving layouts to accommodate inventory changes. Brixel’s solutions re-imagine static walls as movable, functional canvases.\nMaterial Bank\nFounded in 2017, Material Bank partners with leading manufacturers to provide a central catalog of finishings, textiles, wallcoverings, and more. Users can select free samples to touch and test.\nBy consolidating samples sourcing, Material Bank saves designers time hunting specifications. Brand partners gain a promotional channel to reach potential specifiers. For any firm struggling to evaluate options, Material Bank delivers on-demand tactile sampling.\nWoHo\nFounded in 2018, WoHo manufactures interchangeable wall panels, windows, roofs, and more that are assembled on-site into residential or commercial spaces. The components enable mass customization.\nBy standardizing core building blocks, WoHo introduces manufacturing efficiencies to construction. Assembling their puzzle-like parts slashes projects timelines and costs.\nMonograph\nFounded in 2017, Monograph aims to modernize the administrative side of running design practices. Features like time tracking and budget management simplify business operations.\nThe software centralizes firm workflows to improve efficiency. Architects gain business visibility while streamlining team coordination. For studios struggling with scattered systems, Monograph brings much-needed coherence.\nCove.Tool\nLaunched in 2017, Cove.Tool evaluates structures based on metrics like carbon emissions, water usage, and human health impacts. The app then identifies improvement opportunities through data-driven insights.\nBy quantifying environmental impact, Cove.Tool aims to encourage regenerative design. Their assessments empower the iterative enhancements needed to meet green building targets.\nEcoworks\nFounded in 2000, Ecoworks leverages 3D modeling, VR, and other technologies to optimize renovations around sustainability. Their data-driven upgrades reduce waste and environmental impact.\nBy rethinking restoration with green principles in mind, Ecoworks unlocks substantial footprint reductions from existing buildings. Their digitally enhanced solutions deliver resource efficiency at scale.\nCapmo\nFounded in 2018, Capmo centralizes planning documentation, task management, approvals, and project insights on one platform. Teams collaborate while workflows stay organized.\nBy removing information silos, Capmo gives all stakeholders transparency into real-time progress. Their connected system aims to keep builds on schedule and on budget.\nCanibuild\nFounded in 2018, Canibuild facilitates centralized BIM models linking key project stakeholders. Teams manage 3D designs, documentation, issue tracking, and more through the platform.\nBy unifying the design process digitally, Canibuild aims to remove productivity barriers caused by information silos. The ability to coordinate in one system unlocks faster design iteration and decision making.\nMADE Renovation\nFounded in 2011, MADE handles bathroom projects end-to-end, from concept to completion. Their in-house team of designers, project managers, and builders coordinates the transformation.\nBy centralizing services, MADE streamlines bathroom renovations into one efficient process. Their full-service model removes the hassles of coordinating various vendors and contractors.\nFalconViz\nFounded in 2018, FalconViz performs automated drone flights to collect high-resolution spatial data. Advanced sensors and computer vision convert images into detailed 3D site models and analytics.\nBy harnessing autonomous drones, FalconViz enables rapid topographic intelligence. This unlocks insights previously hindered by time and access constraints. For teams needing frequent project visibility, FalconViz delivers regular high-precision aerial tracking.\nHigharc\nFounded in 2021, Higharc streamlines the path from concept to buildable design through automation features. Architects sketch floorplans which Higharc develops into complete model sets.\nBy handling repetitive design system tasks, Higharc enables architects to focus creativity on client needs. The platform cuts weeks from project timelines through its intuitive digital workspace.\nPlanRadar\nFounded in 2012, PlanRadar digitizes workflows for task management, collaboration, issue tracking, and more—all accessible via web and mobile apps. The unified system replaces scattered paper trails and siloed data.\nBy consolidating the abundance of project information into one source of truth, PlanRadar increases transparency and accountability. Their streamlined communication aims to deliver builds safer, faster, and more profitably.\necoworks\nFounded in 2000, ecoworks leverages modular components, 3D modeling, and sustainable materials to optimize for reduced environmental impact. Their streamlined approach also cuts costs and project timelines.\nBy rethinking development with both regeneration and efficiency in mind, ecoworks unlocks substantial footprint reductions. Their solutions scale environmental excellence through technological enhancements.\nDEEPEXI\nFounded in 2017, DEEPEXI’s platforms aim to streamline the process of scaling digital solutions through automation and analytics. This includes managing APIs, measuring adoption, ensuring quality, and more.\nBy providing the missing infrastructure to take digital products live and optimize them, DEEPEXI helps companies hit ROI goals faster. Their tools bridge the gap between digital transformation strategy and execution.\nHouzz\nLaunched in 2009, Houzz offers articles, photos, product recommendations, and reviews organized by style and room. Visitors can also view portfolios and contact home professionals like contractors.\nBy centralizing residential project planning resources, Houzz has become the go-to home improvement destination. Their visual content and contractor marketplace cater to the complete home project journey.\nMILES\nFounded in 2015, MILES transforms underutilized spaces into hubs for local vendors, cultural programming, and community events. Their pop-ups bring energy to neighborhoods while providing affordable retail opportunities.\nBy catalyzing communities around temporary interventions, MILES pioneers an accessible model to test new business concepts. Their experimentation unlocks economic and social value from overlooked urban areas.\nKonstru\nFounded in 2018, Konstru centralizes coordination of BIM models and drawings, enabling streamlined design collaboration. Teams can synchronize changes across Revit, Rhino, and other platforms.\nBy maintaining a unified view of the latest models, Konstru aims to remove productivity bottlenecks caused by scattered BIM data. The ability to track revisions and standardize deliverables unlocks faster design iteration.\nConclusion\nThe world of architecture is being radically transformed by a new wave of innovative startups. While risks and challenges remain, the success of these architecture startups demonstrates the massive potential for entrepreneurs and innovators to transform architecture for the better.\nDiscover more creative startups that might interest you:\nEntertainment startups\nthat are using tech to change the entertainment industry.\nThe best\nfashion startups\nyou need to keep an eye on.\nCreative\nrenewable energy startups\nthat are on a mission to cleaner Earth.\n3D printing companies\nwith outstanding innovations to improve manufacturing.\nSuccessful\nsheet metal companies\nwith the smartest techniques of metal fabrication.\nRelated Articles\nSee All Categories\n10 essential tips to manage a small law firm\nOct 4, 2024\nIn this article we will explore the essential areas and tips that small law firm leaders should prioritize in order to manage and ensure their firm’s success.\nread more\nBusiness development tips for junior professionals\nSep 12, 2024\nIn this article we will discuss more about business development strategies and tips for junior professionals, from networking to using digital tools.\nread more\n11 family business ideas for starting a family-owned company in 2025\nSep 12, 2024\nDo you have some brilliant family business ideas, but you don’t know how to incorporate them into a business? This article will show you what you need to know.\nread more\n10 essential tips to manage a small law firm\nOct 4, 2024\nIn this article we will explore the essential areas and tips that small law firm leaders should prioritize in order to manage and ensure their firm’s success.\nread more\nBusiness development tips for junior professionals\nSep 12, 2024\nIn this article we will discuss more about business development strategies and tips for junior professionals, from networking to using digital tools.\nread more\nMost Popular\n25 powerful work-life balance quotes for better boundaries\n28 Feb, 2025\nBest practices for launching a software MVP\n28 Feb, 2025\nHow can I find caregivers with flexible scheduling options\n27 Feb, 2025\nHow does mobile IV therapy work\n27 Feb, 2025\nHow Gen Z is redefining the workplace and breaking toxic hustle culture\n27 Feb, 2025', 'image_urls': [{'url': 'https://enterpriseleague.com/blog/wp-content/uploads/sidebar-banner-top.png', 'score': 2}, {'url': 'https://enterpriseleague.com/blog/wp-content/uploads/sidebar-banner-bottom.png', 'score': 2}, {'url': 'https://enterpriseleague.com/blog/wp-content/uploads/top-architecture-startups.png', 'score': 1}, {'url': 'https://enterpriseleague.com/blog/wp-content/uploads/top-startups-banner.png', 'score': 1}, {'url': 'https://enterpriseleague.com/blog/wp-content/uploads/top-startups-banner.png', 'score': 1}], 'title': '17 architecture startups to keep an eye on in 2025'}, {'url': 'https://archinect.com/c4ablog/top-architecture-firms-leading-the-future-of-ai-innovation-in-design', 'raw_content': "Top Architecture Firms Leading the Future of AI Innovation in Design | Blogs | Archinect\nSubmit\nShare/Follow\nFeatures\nNews\nEvents\nCompetitions\nJobs\nTalent Finder\nActive Employers\nPeople\nFirms\nBlogs\nForum\nWork Updates\nSchools\nSchool Blogs\nForum\nAbout Archinect\nAdvertising\nContact Us\nNewsletters\nPrivacy Policy\nFeatures\nNews\nJobs\nTalent Finder\nPeople\nFirms\nBlogs\nForum\nSchools\nSchool Blogs\nAbout\nAdvertising\nContact\nNewsletters\nPrivacy\nSearch Archinect\nConsulting For Architects, Inc. Hiring Trends.\nDesign and Manage Your Career\nanchor\nTop Architecture Firms Leading the Future of AI Innovation in Design\nBy\nDavid C. McFadden\nJan 23, '25 2:29 PM EST\n0\n0\nFollow\nAs artificial intelligence in architecture continues to make waves in the design and construction industries, architecture firms harness AI to enhance creativity, sustainability, and efficiency in building design. The rise of AI generative design and computational design in architecture allows firms to create innovative structures that are both beautiful and highly functional. In this blog, we explore the top firms at the forefront of AI-driven architecture and sustainability, shaping the future of the built environment.\n1. Zaha Hadid Architects: Pioneers in AI-Driven Design\nZaha Hadid Architects (ZHA) has been a leader in integrating artificial intelligence into architecture to push the boundaries of traditional design. Using AI generative design, ZHA can create complex, organic forms that defy conventional architectural practices. By utilizing computational design in architecture, the firm can optimize the aesthetics and performance of its structures, making it an industry trailblazer in employing AI to create groundbreaking architecture.\n2. Bjarke Ingels Group (BIG): AI and Urban Design Innovation\nBjarke Ingels Group (BIG) has embraced AI and parametric design to revolutionize urban planning and building design. The firm employs machine learning in urban planning to optimize its projects’ energy efficiency and sustainability. BIG’s commitment to AI-driven architecture and sustainability ensures that its designs are visually striking and environmentally responsible, leading toward more sustainable and intelligent cities.\n3. Foster + Partners: Integrating AI for Smart Buildings\nFoster + Partners is at the cutting edge of AI-driven architecture and sustainability. The firm uses AI to optimize energy efficiency and integrate innovative technologies into its designs. Incorporating artificial intelligence into architecture creates buildings that are adaptive to changing environmental conditions, ensuring long-term sustainability and performance. Its focus on sustainable AI architecture helps pave the way for more resilient and energy-efficient buildings in the future.\n4. AI SpaceFactory: AI and 3D Printing for Future Architecture\nAI SpaceFactory is responsible for combining AI generative design with 3D printing technologies to create innovative and sustainable architectural solutions. Their work, including designing Mars habitats, demonstrates the potential for AI-driven architecture on Earth and beyond our planet. By focusing on sustainable materials and efficient design, they create architecture that minimizes waste, making them a key player in sustainable AI architecture.\n5. Kohn Pedersen Fox (KPF): Data-Driven AI for Sustainable Architecture\nKohn Pedersen Fox (KPF) leverages machine learning in urban planning to analyze large datasets and optimize the design and performance of buildings. Their integration of AI-driven architecture and sustainability helps them create more intelligent and efficient cities. KPF uses AI to assess the environmental impact of its buildings, reduce energy consumption, enhance sustainability, and position itself as a leader in sustainable AI architecture.\n6. Gensler: Leveraging AI to Design Smarter Spaces\nGensler uses artificial intelligence in architecture to design more innovative and flexible spaces. By incorporating AI tools, they analyze patterns in user behavior to create adaptable workspaces, commercial environments, and urban spaces. Their emphasis on AI-driven architecture and sustainability ensures that these spaces are functional and environmentally responsible, making Gensler stand out in sustainable AI architecture.\n7. Morphosis Architects: AI and Environmental Performance\nMorphosis Architects combines computational design in architecture with AI to create high-performance buildings. The firm uses AI to visualize complex geometries and analyze environmental data, optimizing energy use and sustainability. Their focus on AI-driven architecture and sustainability enables them to design innovative buildings that perform efficiently, with a minimal ecological impact, pushing the boundaries of sustainable AI architecture.\n8. Skidmore, Owings & Merrill (SOM): AI for Optimizing Building Performance\nSkidmore, Owings & Merrill (SOM) utilizes AI and parametric design to optimize building design, construction, and long-term performance. Through AI-driven architecture, SOM integrates real-time environmental data to improve the energy efficiency of its buildings and ensure that they meet the evolving needs of cities. Their commitment to sustainable AI architecture ensures their designs are both high-performance and future-proof.\n9. The Living (by David Benjamin): AI and Bio-Inspired Architecture\nThe Living, led by architect David Benjamin, uses AI generative design to create bio-inspired architecture. Their adaptive façades, which respond to environmental changes, are a prime example of how AI-driven architecture and sustainability can create buildings that reduce energy consumption and adapt to their surroundings. By combining computational design in architecture with bio-inspired principles, The Living is creating architecture that is both sustainable and responsive to its environment.\n10. Heatherwick Studio: AI for Sustainable, Adaptive Designs\nHeatherwick Studio uses AI generative design to explore various design possibilities and optimize the sustainability of its buildings. Their projects show how AI-driven architecture can help create adaptive and energy-efficient designs. With a focus on sustainable AI architecture, Heatherwick Studio is pushing the limits of what is possible, combining cutting-edge technology with innovative design to create beautiful and functional buildings.\nConclusion: The Future of Architecture is AI-Driven\nAs artificial intelligence in architecture continues to evolve, more firms are using AI to create thoughtful, sustainable buildings. From AI generative design to AI-driven architecture and sustainability, these firms harness AI’s power to transform how we design and build our cities. By integrating computational design in architecture, machine learning in urban planning, and sustainable AI architecture, they are shaping the future of architecture and ensuring that the buildings we create are beautiful, functional, efficient, and environmentally responsible.\nThe future of architecture is here—and AI powers it.\nTop 10 Hashtags for Architecture and AI\n#AIinArchitecture, #AIGenerativeDesign, #SustainableAIArchitecture, #MachineLearningInUrbanPlanning, #AIandParametricDesign, #AIandArchitecture, #GenerativeDesign, #SmartBuildings, #ComputationalDesignInArchitecture, #ArchitectureInnovation\nReferences\nZaha Hadid Architects (ZHA)\n– Official website:\nhttps://www.zaha-hadid.com/\nBjarke Ingels Group (BIG)\n– Official website:\nhttps://big.dk/\nFoster + Partners\n– Official website:\nhttps://www.fosterandpartners.com/\nAI SpaceFactory\n– Official website:\nhttps://www.aispacefactory.com/\nKohn Pedersen Fox (KPF)\n– Official website:\nhttps://kpf.com/\nGensler\n– Official website:\nhttps://www.gensler.com/\nMorphosis Architects\n– Official website:\nhttps://morphosis.com/\nSkidmore, Owings & Merrill (SOM)\n– Official website:\nhttps://www.som.com/\nThe Living (by David Benjamin)\n– Official website:\nhttps://www.thelivingstudio.com/\nHeatherwick Studio\n– Official website:\nhttps://www.heatherwick.com/\nChatGPT 4\n– Generated with the assistance of ChatGPT 4, a language model developed by OpenAI.\nThese websites will provide you with deeper insights into the firms’ work, their use of AI in architecture, and their contributions to the future of design and sustainability. Additionally, for more in-depth industry articles or research papers, websites like\nArchDaily\n(\nhttps://www.archdaily.com/\n),\nDezeen\n(\nhttps://www.dezeen.com/\n), and\nAIArchitect\n(\nhttps://www.aia.org/\n) are excellent resources.\nAbout the author\nDrawing upon original ideas and extensive personal and professional experience in the field, David McFadden crafted this article to explore the latest trends in architecture and building design. After working at various design practices—both full-time and freelance—and launching his design firm, David identified a significant gap in the industry. In 1984, he founded Consulting For Architects Inc. Careers, an expansive hub designed to align architects with hiring firms for mutual benefit. This platform enables architects to find impactful design work and frees hiring firms from the time-consuming cycles of recruitment and layoffs. David’s innovative approach to employer-employee relations has brought much-needed flexibility and adaptation to the industry. As the Founder and CEO, David has successfully guided his clients and staff through the challenges of four recessions—the early ’80s, early ’90s, early 2000s, the Great Recession, the pandemic, and the current slowdown due to inflation and high interest rates.\nTagged\n#aiinarchitecture #aigenerativedesign\n#sustainableaiarchitecture\n#machinelearninginurbanplanning\n#aiandparametricdesign\n#aiandarchitecture\n#generativedesign\n#smartbuildings\n#computationaldesigninarchitecture\n#architectureinnovation\nBack to Top ↑\nNo Comments\nBlock this user\nAre you sure you want to block this user and hide all related comments throughout the site?\nArchinect\nThis is your first comment on Archinect. Your comment will be visible once approved.\nBack to Entry List...\n×\nSearch in:\nAll of Archinect\nFeatures\nNews\nFirms\nSchools\nPeople\nForum\nJobs\nBlogs\nBlog Posts\nSubscribe to this Blog\nAbout this Blog\nStaying on top of hiring trends in one of the most volatile professions is required reading. New information to help you make better career choices empowering you to design and manage your own career. Our blog is written for design professionals by design professionals. Whether you are in school or are at the peak of your architecture career you will benefit by following and subscribing to this blog. #cons4arch #ilookup #architecture #careers #employment #jobs #recruiters\nAffiliated with:\nConsulting For Architects, Inc. Careers\nAuthored by:\nDavid C. McFadden\nNew York, NY, US\nRecent Entries\nTop Architecture Firms Leading the Future of AI Innovation in Design\nJan 23 '25\nThe Impact of 3D-Printed Prefabricated Buildings on Housing, Architecture, and Construction\nSep 18 '24\nNavigating Office Perks: Insights for Small Architecture and Design Firms in NYC\nMar 20 '24\n“Reimagining Legacy: Philip Johnson’s Glass House Achieves LEED Platinum Excellence”\nSep 21 '23\nCritiquing The Line: Unraveling the Mathematical Debate Behind Saudi Arabia’s Unique Megaproject\nSep 13 '23\nBusiness and Entrepreneurship in Architecture\nMar 15 '23\n8 Factors that Affect an Architect’s Salary\nMar 7 '23\nMy professors said I wouldn’t make money\nFeb 17 '23\nLEED Certification 101\nJan 17 '23\nArchitecture Firm Owners and Employees Continue to Weigh Trade Unions\nDec 15 '22\nWorld-destroying Architects Wanted\nNov 7 '22\nEnd of the Road For the Gig Economy?\nNov 3 '22\nIncrease Your Bottom Line and Keep Your Employees Happy\nOct 25 '22\nBenefits of Working in Architecture on a Project Basis\nOct 10 '22\nThe (Post-Pandemic) Job Hunt\nSep 29 '22\nThe Hiring War To Find And Retain Architecture And Design Talent\nSep 27 '22\nFeeling Glum in Your Current Architect or Design Job? Here's How to Beat the Blues, Stop Working Overtime, and Earn a Decent Salary\nFeb 5 '20\nToo Many Options? How to Decide Between Multiple Architect Positions the Professional Way\nApr 16 '19\nThe Female Architects—Surviving the Journey to the Top\nApr 4 '19\nThe 3 Best Cities for Architecture Careers\nJul 16 '18\nAre you Hiring Top Talent, or is your Competitor?\nJun 27 '18\nHow to Make the Most of Entry-Level Architecture Jobs\nJun 25 '18\nThe 4 Best Architecture Related Careers for New Graduates\nJun 12 '18\nHiring millennial architects & designers & what is important to them\nApr 25 '16\nHow to transform independent contractors into employees\nApr 5 '16\nMillennials in the architecture workplace\nDec 30 '15\nHappy Architects\nMay 29 '15\nEmployers Ask: “Where Are The Qualified Architects?” They All Got Jobs.\nFeb 2 '15", 'image_urls': [], 'title': 'Top Architecture Firms Leading the Future of AI Innovation in Design | Blogs | Archinect'}, {'url': 'https://community.intel.com/t5/Blogs/Tech-Innovation/Artificial-Intelligence-AI/Deciphering-the-AI-Startup-Ecosystem-Insights-from-the-Intel/post/1656987', 'raw_content': "AI Startup Insights: Key Trends from Intel® Liftoff’s 2024 Report\nSearch\nArtificial Intelligence (AI)\nDiscuss current events in AI and technological innovations with Intel® employees\nSuccess! Subscription added.\nSuccess! Subscription removed.\nSorry, you must verify to complete this action. Please click the verification link in your email. You may re-send via your\nprofile\n.\nIntel Community\nBlogs\nTech Innovation\nArtificial Intelligence (AI)\nDeciphering the AI Startup Ecosystem: Insights from the Intel® Liftoff AI Startups Index Report\n681 Discussions\nDeciphering the AI Startup Ecosystem: Insights from the Intel® Liftoff AI Startups Index Report\nSubscribe\nArticle Options\nSubscribe to RSS Feed\nMark as New\nMark as Read\nBookmark\nSubscribe\nPrinter Friendly Page\nReport Inappropriate Content\nJade-Worrall\nEmployee\n\u200e01-16-2025\n12:00 AM\n0\n0\n1,755\nEveryone has an opinion about artificial intelligence & AI innovation, because we all get to see it transforming our work and our daily lives in front of us. But how often do we get to look behind the scenes to see what’s actually driving it all?\nHow much is really known about the thriving ecosystem of AI startups - small but mighty innovators turning big ideas into transformative solutions?\nIntel’s\nAI Startup Index Report 2024,\npublished by Intel® Liftoff for AI Startups, offers an insider’s view into the global startup ecosystem, uncovering key trends, challenges, and opportunities shaping the future of generative AI and AI powered innovation.\nFeatured Startups\nSpySkyTech\nLokal Ed\nReama AI\nAlignment Lab AI\nExpanso\nQuantum Photonics\nAleph Innovations\nBezoku\nVenturely\nPeopleSense.AI\nNoodle4\nKamiwaza Corp\nHEMOTAG\nTinypesa\nKode AI Limited\nUltralytics\nCerebraAI\nkAI\nSpiky.ai\nBloombase\nNet AI\nEpochZero\nMicroFuse Technologies\nTECNOSIA OÜ\nKalio\nSpooler\nModus Africa\nConverge Bio\nStarwit Technologies GmbH\nDeepLeaf\nEnkrypt AI\nCLIKA\nSelecton Technologies\nQbeast\nEdgeRunner AI\nCloudConstable Inc\nFlexAI\nWaveye\nZerve AI\nHasty.ai\nPixel ML\nEpix AI\nFiveBrane\nGenVR Research\nSplxAI\nToumAI\nMizizi Ai\nParavox AI\nTolveet LLC\nVOTIX\nLubu Technologies\nLastMinute\nUnsloth AI\nUndefine\nHear From the Startups\n“\nAI for everyone: AI native apps and specialized model deployment will dominate future landscapes..\n.” - Kelvin Perea, kAI\n“\nOpen-source enables faster development, is transparent, and creates trust.\n” - Markus Kett, MicroStream Software\n“\nThe Open Source movement is the single biggest driver of AI innovation. It is at risk of over-regulation from bad actors with their own agenda.\n” - Laura Hohmann, Expanso\n“In the next 3-5 years, significant AI trends will likely include the rise of foundation models, widespread adoption of AI in healthcare, and increased focus on ethical AI and regulation.\n” - Timur Tuspayev, Cerebra AI\n“\nAI systems will focus on continual learning, allowing models to adapt and update in real-time, making them more flexible and efficient.\n” - Emmanuel Ugwu, MicroFuse Technologies\n“\nThe practical utility of customizable models will outpace non-personalized options, creating a new market of utilities and solutions as frameworks mature\n” - John Cook, Alignment Lab AI\n“\nGenerative AI advancements will continue to revolutionize content creation and synthetic data, enabling faster decision-making and real-time analytics at the edge for smarter IoT and autonomous systems.\n” - Harsh Verma, PeopleSense.AI\nThe Engine of Transformation: AI Startups\nAI startups are the unsung heroes of the moment we are living through. While their innovations are (rightfully) in the limelight, the startups themselves - the brains and brawn behind it all - receive less attention. We believe that’s an oversight that we are in the best possible position to correct, because we’re at ground zero with some of the best and brightest of them all - not only in silicon valley, but around the globe.\nThis report aims to take their unique challenges and perspectives, and package them in a digestible format for anyone who has a stake in the past, present and future of AI.\nKey Trends from the Report\nThe\nIntel® Liftoff AI Startup Index Report 2024\nhighlights several emerging trends and obstacles:\nHealthcare and IT Dominate\n: Healthcare and IT account for the lion’s share of startups, followed by other popular categories like energy, finance, manufacturing and customer service.\nGo-to-Market Challenges\n: Interestingly, attracting funding and venture capital didn’t crack the top spot on the list of startup challenges. That went to go-to-market executions. Effective marketing and customer acquisition strategies are critical for scaling and attracting investors - and according to most of the startups we asked, it’s keeping them up at night\nDiverse Technology Adoption\n: Startups are adventurous when it comes to trying new tools. We found a wide spread of technologies in use, including cloud services like AWS and Microsoft Azure, as well as Intel’s cutting-edge resources like\nIntel® Tiber™ AI Cloud\nand OpenVINO™. If it works, startups will adopt it.\nIntel® Liftoff: An Accelerator Empowering AI Startups\nIntel® Liftoff for Startups is a global virtual accelerator built so support organizations like early-stage AI companies with tailored resources:\nTechnical Expertise\n: Startups receive direct mentorship and training to expedite product development and market entry.\nTechnology Access\n: Cutting-edge computing resources like the Intel® Tiber™ AI Cloud streamline testing, development, and scaling.\nGo-to-Market Support\n: Strategic guidance in marketing and networking positions startups for competitive success.\nIn just two years, Intel® Liftoff has supported\n160 AI startups and 3,000 developers\n, enabling breakthroughs such as distributed GPU workloads and LLM-as-a-service.\nInsights from a Wide Range of Founders and Community Leaders\nThe report captures the voices of AI startup founders, offering a rare glimpse into their journeys. The insights we’ve gained highlight both the obstacles and opportunities faced by the next generation of innovators. This survey not only illuminates the challenges but also provides actionable guidance for fostering a more resilient AI startup ecosystem.\nEugenie Wirz, Program Lead at Intel® Liftoff, emphasizes the human aspect of AI innovation: “This report highlights the AI startup ecosystem and the potential unlocked when innovation is given space to grow. Through our collaboration, Intel® Liftoff helps founders transform their visions into solutions that push the boundaries of AI.”\nHarmen Van der Linde, Senior Director / Head of Product Management - Intel® Tiber™ AI Cloud states, “At Intel, our goal is to strengthen AI through acceleration. By supporting startups with our AI cloud solution, we provide the computing power and resources they need to scale, innovate, and overcome challenges. Intel® Tiber™ AI Cloud is designed to empower the next wave of AI innovation, ensuring startups have the support to drive transformative change.”\nAlong with the world-class technical support they receive, participants also get to join one of the most dynamic startup communities in the world, set up specifically to serve the networking and business needs of AI companies.\nA Roadmap for the Future\nAs the AI ecosystem continues to evolve at breakneck speed, the Intel® Liftoff AI Startup Index Report provides a much-needed snapshot of where we are right now. It’s a must-read for:\nInvestors\nseeking data-driven insights to identify high-potential opportunities.\nPolicymakers\ninterested in leading strategies to support AI-driven economic growth.\nResearchers\nwho need to understand the dynamics of AI innovation.\nStartups\nwho are open to learning from their peers and adapting their best ideas.\nBy highlighting the successes and struggles of early-stage AI companies, the report shines a light on their impact, and also sets the stage for future growth. With the right support systems, these startups can continue to drive innovation, redefine industries, and unlock the as yet unknown potential of artificial intelligence.\nTo dive deeper into these insights and learn more about the Intel® Liftoff program,\ndownload the full\nAI Startup Index Report\nhere.\nTags\n(5)\nTags:\n@intel\nBlogs\nintel community\nIntel Liftoff\nWe Are Intel\n0\nKudos\nAbout the Author\nAs a Software Tools Ecosystem Specialist at Intel, I’ve had the privilege of working on the dynamic GenAI initiative. My focus is on driving engagement with the software developer audience. I'm a proud team member of the Intel® Liftoff for Startups and the Developer Engagement, Relations, and Studio team.\nYou must be a registered user to add a comment. If you've already registered, sign in. Otherwise, register and sign in.\nComment\nCommunity support is provided Monday to Friday. Other contact methods are available\nhere\n.\nIntel does not verify all solutions, including but not limited to any file transfers that may appear in this community. Accordingly, Intel disclaims all express and implied warranties, including without limitation, the implied warranties of merchantability, fitness for a particular purpose, and non-infringement, as well as any warranty arising from course of performance, course of dealing, or usage in trade.\nFor more complete information about compiler optimizations, see our\nOptimization Notice\n.\n©Intel Corporation\nTerms of Use\n*Trademarks\nCookies\nPrivacy\nSupply Chain Transparency\nSite Map", 'image_urls': [], 'title': '\n\tAI Startup Insights: Key Trends from Intel® Liftoff’s 2024 Report\n'}, {'url': 'https://startup.info/best-ai-startups/', 'raw_content': 'Top 20 AI Startups To Watch in 2025\nConnect with us\nShare\nTweet\nThe field of artificial intelligence (AI) has been advancing at breakneck speed, influencing industries from healthcare and finance to entertainment and agriculture. As more organizations recognize the competitive edge that data-driven insights and automation can provide, the AI market continues to surge. According to the\nAI Index Report\nfrom Stanford University, the AI ecosystem is seeing exponential investment, research breakthroughs, and adoption rates—trends that show no signs of slowing down as we approach 2025.\nIn this comprehensive overview, we will delve into 20 of the most promising AI startups you should keep on your radar. Whether they specialize in natural language processing (NLP), computer vision, MLOps, robotics, or generative AI, these companies are tackling complex challenges while shaping the future of technology as we know it. If you’re searching for insights into groundbreaking innovations, best practices in AI, and how these trailblazing companies are poised to redefine entire sectors, you’re in the right place.\nFrom startups refining advanced NLP models to ventures revolutionizing manufacturing with computer vision, each company on this list brings a unique perspective and specialized approach to the world of AI. We will explore not only their flagship products and services but also their market traction, partnerships, and visions for long-term growth. By the end of this article, you’ll have a 360-degree overview of where the AI world is headed—making it easier for you to invest, collaborate, or simply stay informed about the cutting edge of technology.\nSo, let’s dive in.\nTable of Contents\nToggle\n1. Anthropic\nOverview\nAnthropic is an AI safety and research company founded by veterans from OpenAI. With a mission to create “safe AI” that can be reliably aligned with human values, Anthropic focuses on ensuring that as machine intelligence grows in capabilities, it remains beneficial and does not lead to unintended consequences.\nInnovation\nConstitutional AI\n: Anthropic introduced an approach called “Constitutional AI,” aimed at giving large language models explicit guidelines for ethical behavior.\nMulti-modal Capabilities\n: Although primarily known for text-based generative models, the company also invests in multi-modal technologies that incorporate images and speech.\nWhy It Stands Out\nAnthropic’s emphasis on AI safety sets it apart from many of its contemporaries, and this focus resonates strongly with regulators, researchers, and industry stakeholders. With consumer awareness around AI ethics growing, Anthropic is positioned to influence the broader conversation about responsible AI deployment.\n2. Hugging Face\nOverview\nHugging Face started as a\nchatbot app\nbut has evolved into one of the most influential open-source machine learning platforms globally. The company’s primary objective is to democratize AI by offering a repository of ready-to-use models and datasets.\nInnovation\nTransformers Library\n: Hugging Face’s Transformers library has become a staple for NLP researchers and developers alike. It simplifies access to state-of-the-art models like BERT, GPT, and RoBERTa.\nOpen Collaboration\n: Their platform enables a vibrant community of AI researchers, data scientists, and developers to collaborate on model improvement and dataset creation.\nWhy It Stands Out\nHugging Face revolutionized how machine learning projects are launched, scaled, and shared. The user-friendly interfaces and community-driven approach significantly reduce barriers to entry. Not just for large corporations, their tools are equally useful for indie developers and academic researchers.\n3. Cohere\nOverview\nCohere is an NLP-focused startup that builds large language models for enterprise applications. By offering powerful text generation and understanding capabilities, Cohere aims to embed intelligent conversational interfaces and analytics into every layer of a business.\nInnovation\nEnterprise-grade NLP\n: Cohere’s services are designed to handle extensive enterprise demands, focusing on scalability and security.\nDeveloper-centric Tools\n: The platform provides easy-to-use APIs and SDKs, reducing the complexities of integrating NLP solutions into existing infrastructures.\nWhy It Stands Out\nWhat makes Cohere a vital startup to watch is its clear focus on bridging the gap between research-grade models and actionable enterprise use cases. They continually refine their models for better accuracy, faster inference, and lower computational cost, making advanced AI more accessible to businesses.\n4. Inflection AI\nOverview\nInflection AI specializes in developing advanced conversational agents that utilize large language models to create more natural and intuitive user interactions. The startup’s technology is used in a variety of applications, ranging from virtual assistants to customer service bots.\nInnovation\nContextual Memory\n: Inflection AI’s models are designed to maintain context over longer conversations, reducing repetition and improving overall coherence.\nEthical AI\n: Like many forward-thinking AI startups, Inflection AI prioritizes ethical guidelines to ensure user data is processed responsibly.\nWhy It Stands Out\nThe ability to maintain extended, context-rich conversations is a milestone for generative AI applications. Inflection AI’s focus on refining these capabilities could reshape how companies handle customer interactions, making it one of the most potentially disruptive startups in the conversational AI space.\n5. Stability AI\nOverview\nKnown for creating open-source models in the world of generative AI, Stability AI burst onto the scene with text-to-image software such as Stable Diffusion. The company’s mission is to make AI tools publicly accessible and to encourage open innovation.\nInnovation\nStable Diffusion\n: A groundbreaking text-to-image generative model that allows anyone to create highly detailed images using plain text prompts.\nOpen-source Approach\n: Unlike some competitors that keep their best models behind paywalls, Stability AI’s strategy revolves around transparency and community collaboration.\nWhy It Stands Out\nStability AI democratizes powerful generative technologies that were once the exclusive domain of large tech companies. In doing so, the startup has sparked a wave of creative applications, from digital art to rapid prototyping in industrial design, illustrating the limitless possibilities of open-source AI.\n6. Runway\nOverview\nRunway is at the forefront of video editing and generative AI, helping content creators, studios, and marketers produce high-quality visuals without the need for expensive equipment or complex software. By merging machine learning with intuitive design, the company provides next-generation editing tools.\nInnovation\nAI-powered Video Editing\n: Users can remove backgrounds, upscale resolution, and even alter scenes in real-time.\nGenerative Media Tools\n: Runway’s newest features enable the synthesis of 3D assets and video elements, reducing production time dramatically.\nWhy It Stands Out\nVideo is the fastest-growing form of digital content consumption. Runway’s cutting-edge tools cater to professionals and amateurs alike, paving the way for more immersive storytelling and more efficient content production pipelines. As we move toward 2025, the demand for quality video content will only grow, placing Runway in an enviable market position.\n7. Adept AI\nOverview\nAdept AI focuses on building “AI teammates” that can automate a broad range of digital tasks. From sorting emails to data entry, Adept’s systems observe user actions and then replicate them at scale, thereby increasing productivity and reducing human error.\nInnovation\nTask Automation\n: Adept AI’s platform learns from user behavior, enabling it to identify repetitive tasks and find ways to streamline them.\nAdaptive Learning\n: The technology adapts to individual work styles, refining its recommendations and actions over time.\nWhy It Stands Out\nAdept AI is essentially bridging the gap between robotic process automation (RPA) and generative AI. As businesses increasingly look to optimize workflows and cut operational costs, Adept AI’s scalable and adaptive approach makes it one of the most intriguing new players in enterprise AI automation.\n8. Character.ai\nOverview\nCharacter.ai develops immersive chatbot experiences that mimic specific personas or historical figures. Designed initially for entertainment and education, the company’s sophisticated language models are now finding use cases in training simulations and interactive marketing.\nInnovation\nPersona-based Chatbots\n: By tapping into large language models, Character.ai creates extremely believable personalities that can even emulate speech patterns of well-known characters.\nMultilingual Support\n: The platform is expanding to accommodate multiple languages for a global user base.\nWhy It Stands Out\nThe allure of engaging with a hyper-realistic virtual entity has far-reaching applications—from language learning to brand promotion. Character.ai’s dedication to authenticity and user-friendly design makes them a unique and culturally relevant AI venture.\n9. Mistral AI\nOverview\nBased in Europe, Mistral AI is a rising star in the generative AI landscape, with an emphasis on building compact yet powerful models. Their solutions target a variety of sectors, including healthcare, finance, and e-commerce, offering AI-driven recommendations and analytics.\nInnovation\nLightweight Models\n: Mistral AI invests heavily in research to reduce model size while maintaining or even improving performance. This lowers hardware requirements and speeds up deployment.\nVertical Solutions\n: The startup packages specialized models for different industries, allowing for smoother integration and faster ROI.\nWhy It Stands Out\nMistral AI’s focus on efficient, smaller-scale models fills a notable gap in the market. This is especially important for companies that don’t have the budget or computational resources to handle massive AI implementations. By doing more with less, Mistral AI positions itself as a game-changer in democratizing sophisticated AI capabilities.\n10. Modular\nOverview\nModular is an infrastructure-focused AI startup that helps organizations optimize their machine learning pipelines from data ingestion to deployment. Their platform is designed to make it easier for enterprises to orchestrate, track, and manage complex ML workflows in a secure environment.\nInnovation\nPipeline Orchestration\n: Modular’s core product streamlines ML pipelines, allowing data scientists to focus more on model building and less on configuration headaches.\nSecurity Features\n: The platform incorporates end-to-end encryption and automated compliance checks, reducing the risk of data breaches.\nWhy It Stands Out\nOne of the largest hurdles in enterprise AI adoption is the complexity of building and maintaining robust ML pipelines. By focusing on modular, plug-and-play infrastructure, the company addresses the immediate needs of businesses looking for reliable, scalable, and secure AI solutions.\n11. Imbue (Formerly Generally Intelligent)\nOverview\nImbue, which rebranded from Generally Intelligent, is a research-driven startup dedicated to unlocking higher-level reasoning in AI models. Through their advanced research, they aim to develop algorithms capable of adaptive learning, even in dynamically changing environments.\nInnovation\nCognitive Architectures\n: Imbue explores architectures that replicate certain aspects of human cognition, such as causal inference and memory retention.\nExploratory Research\n: Beyond product development, the startup collaborates with academic institutions to push the frontier of AI theory.\nWhy It Stands Out\nWhile many AI startups chase commercialization, Imbue takes a research-first approach, ensuring any product or feature is grounded in rigorous experimentation. Their commitment to foundational AI research could lead to breakthroughs that ripple across the entire industry.\n12. MosaicML\nOverview\nRecently acquired by Databricks, MosaicML is known for its specialized expertise in helping companies train large-scale AI models more efficiently. The startup provides software optimizations and algorithmic improvements that can drastically reduce both the time and cost associated with training deep learning models.\nInnovation\nModel Optimization\n: MosaicML’s core offerings focus on optimizing hyperparameters and leveraging distributed computing for training efficiency.\nCost Reduction\n: By fine-tuning resource usage and applying advanced compression techniques, MosaicML can significantly lower cloud computing expenditures.\nWhy It Stands Out\nTraining large-scale models is expensive and time-consuming—a barrier for organizations with fewer resources. MosaicML’s solutions democratize AI by cutting down the overhead, enabling more companies to explore and benefit from advanced machine learning techniques.\n13. Snorkel AI\nOverview\nSnorkel AI is a data-centric AI startup that emphasizes the quality of training data. Their platform provides programmatic labeling and data management solutions, allowing data scientists to rapidly label massive datasets without manual effort.\nInnovation\nWeak Supervision\n: Snorkel AI popularized the concept of weak supervision, a technique where rules, heuristics, and other signals are used to generate large labeled datasets.\nData Iteration\n: The startup encourages iterative refinement of data labels to improve model accuracy over time, minimizing the typical guess-and-check approach.\nWhy It Stands Out\nIn many AI projects, data collection and labeling often overshadow modeling efforts. Snorkel AI targets this bottleneck directly. By making labeling faster and more accurate, the company helps developers bring AI solutions to production sooner and at a fraction of the cost.\n14. Weights & Biases\nOverview\nWeights & Biases (W&B) provides a platform for experiment tracking, model versioning, and collaboration in machine learning projects. It has quickly become a go-to tool for data science teams looking for better transparency and reproducibility.\nInnovation\nReal-time Monitoring\n: The platform offers interactive dashboards that update in real-time, enabling teams to visualize metrics like loss, accuracy, and system resource usage.\nSeamless Integrations\n: W&B integrates with popular ML frameworks like TensorFlow, PyTorch, and Keras, making it easy to plug into existing workflows.\nWhy It Stands Out\nThe complexity of ML experiments can quickly become unmanageable without proper tooling. Weights & Biases addresses this gap by simplifying collaboration and record-keeping, helping data science teams avoid costly mistakes and replicate results.\n15. DataRobot\nOverview\nDataRobot is an AI cloud platform that promises end-to-end automation of machine learning projects. It streamlines tasks such as feature engineering, model selection, and even deployment, opening the door for less technical stakeholders to benefit from AI insights.\nInnovation\nAutoML\n: DataRobot’s Automated Machine Learning platform intelligently chooses the best algorithms and hyperparameters for a given dataset.\nExplainable AI\n: The platform offers interpretability features, giving users insights into how the model arrives at its predictions.\nWhy It Stands Out\nNot every organization has the in-house expertise to develop complex ML models from scratch. DataRobot bridges this talent gap with an automated, user-friendly approach, making advanced analytics accessible to more teams. Their enterprise-grade solutions and support further solidify their reputation.\n16. PathAI\nOverview\nPathAI focuses on AI-driven pathology solutions for healthcare, particularly in cancer research and diagnosis. Their platform applies deep learning to analyze digital pathology slides, identifying complex biomarkers that might be missed by human eyes.\nInnovation\nDisease Detection\n: PathAI’s algorithms have a high degree of accuracy in identifying tumors and other anomalies, speeding up the diagnostic process.\nPredictive Analytics\n: Beyond detection, the startup’s models can predict disease progression and treatment response, aiding personalized medicine.\nWhy It Stands Out\nHealthcare remains one of the most impactful sectors for AI applications, and pathology is a critical step in disease management. PathAI’s breakthroughs not only expedite accurate diagnoses but also stand to improve patient outcomes on a significant scale, making them a crucial player in medical AI.\n17. Vicarious\nOverview\nVicarious aims to build general intelligence for robots through a technology called the Recursive Cortical Network (RCN). The startup envisions a future where robots can learn new tasks with minimal data and quickly adapt to changing environments—much like humans do.\nInnovation\nRecursive Cortical Network\n: Vicarious’s approach attempts to simulate aspects of the human neocortex, responsible for high-level functions such as sensory perception.\nFlexible Robotics\n: By enabling robots to learn in a more generalized manner, Vicarious moves toward reducing the time-consuming task of reprogramming or retraining robots for each new job.\nWhy It Stands Out\nWhile specialized AI is abundant, the quest for more generalized intelligence in robotics remains elusive. Vicarious’s unique methodologies could be a game-changer if they succeed, potentially redefining how robots are utilized in manufacturing, agriculture, and even home environments.\n18. Elementary Robotics\nOverview\nElementary Robotics specializes in computer vision solutions for manufacturing, logistics, and other industrial use cases. Their AI-driven camera systems inspect products on the assembly line, identifying defects in real-time.\nInnovation\nEdge Computing\n: By processing data directly at the edge, Elementary Robotics reduces latency and allows for immediate quality control decisions.\nAutomation Integrations\n: The company’s solutions integrate seamlessly with existing factory setups, minimizing disruptions and downtime.\nWhy It Stands Out\nIn a global market that places increasing emphasis on product quality and operational efficiency, Elementary Robotics addresses a critical need. Automated quality control not only saves time and money but also reduces waste—a key factor for sustainable industrial practices.\n19. Seldon\nOverview\nSeldon provides an open-source MLOps platform that focuses on simplifying the deployment, monitoring, and management of machine learning models. Whether on-premises or in the cloud, Seldon aims to create a frictionless experience from development to production.\nInnovation\nSeldon Core\n: An open-source solution that integrates with Kubernetes for large-scale model serving.\nExplainability Tooling\n: Their product suite includes modules for model explainability, helping teams adhere to ethical and regulatory requirements.\nWhy It Stands Out\nDeploying AI models can be as challenging as developing them, especially at scale. Seldon’s specialized tooling makes it easier for organizations to navigate the complexities of MLOps, ensuring that models are both reliable and transparent in real-world conditions.\n20. Covariant\nOverview\nCovariant focuses on robotic automation in fulfillment centers and warehouses. Their AI-enabled robotic arms can sort, pick, and pack items of varying shapes and sizes, adapting to changes in real time.\nInnovation\nReinforcement Learning\n: Covariant employs advanced RL algorithms that learn from trial and error, continually improving their performance.\nCloud Robotics\n: The company leverages a cloud platform where insights from one robot are shared with others, accelerating the collective learning process.\nWhy It Stands Out\nThe booming e-commerce industry demands efficient and adaptable warehouse operations. Covariant’s robots not only speed up these processes but can also handle tasks that were previously too complex for traditional automation solutions, thus opening up a wider range of industrial applications.\nConclusion\nAs we head into 2025, the AI landscape is as dynamic and thrilling as ever. From companies revolutionizing generative AI and NLP to those spearheading robotics and data-centric solutions, these 20 startups exemplify the diversity and depth of innovation in the field. Each organization has carved out a unique niche—be it through open-source platforms, specialized healthcare applications, AI safety protocols, or transformative enterprise solutions. Taken together, they paint a picture of an industry at the cusp of reshaping how we live, work, and interact with technology.\nAI’s trajectory suggests continued investment, breakthroughs in fundamental research, and growing social discourse around responsible deployment. Initiatives to make AI more accessible, transparent, and ethical will become increasingly vital. Startups like Anthropic and Inflection AI remind us that this technology carries immense power—and with it, the responsibility to guide its development thoughtfully.\nFor entrepreneurs and investors, the opportunities are boundless. Enterprises that integrate AI effectively can gain a decisive competitive edge, while governments grapple with regulatory frameworks that keep pace with innovation. Education will play a key role in preparing a workforce adept at not only coding and data analysis but also the ethical implications and domain-specific contexts in which AI operates.\nIf you are looking to engage with any of these startups—whether to collaborate, invest, or adopt their solutions—now is the time. The AI revolution continues, promising transformative changes in every sector it touches. Staying informed about these leading-edge companies can help you navigate the rapidly evolving tech ecosystem and harness the potential of artificial intelligence in the years to come.\nUltimately, these 20 AI startups represent far more than just next-gen technology; they embody the future of human-machine synergy. By forging better NLP models, ensuring robust MLOps infrastructures, enhancing industrial robotics, and prioritizing ethical guidelines, they pave the way for AI to flourish responsibly. Keep them in your sights and expect great things on the horizon as 2025 approaches.\nRelated Topics:\nKossi Adzo\nKossi Adzo is the editor and author of Startup.info. He is software engineer. Innovation, Businesses and companies are his passion. He filled several\npatents\nin IT & Communication technologies. He manages the technical operations at Startup.info.\nAdvertisement\nYou may like\nClick to comment\nLeave a Reply\nCancel reply\nYour email address will not be published.\nRequired fields are marked\n*\nComment\n*\nName\n*\nEmail\n*\nWebsite\nSave my name, email, and website in this browser for the next time I comment.\nΔ\nMost Read Posts This Month\nResources\n3 years ago\nWhy Companies Must Adopt Digital Documents\nBlogs\n4 years ago\nScaleflex: Beyond Digital Asset Management – a “Swiss Knife” in the Content Operations Ecosystem\nResources\n2 years ago\nA Guide to Pickleball: The Latest, Greatest Sport You Might Not Know, But Should!\nTips and support\n4 months ago\nHow AI is Changing the Job Market: Essential Tips for Professionals to Stay Relevant', 'image_urls': [{'url': 'https://startup.info/wp-content/uploads/2025/01/ai-startups.webp', 'score': 3}], 'title': 'Top 20 AI Startups To Watch in 2025'}, {'url': 'https://www.sequoiacap.com/article/ai-in-2025/', 'raw_content': 'AI in 2025: Building Blocks Firmly in Place | Sequoia Capital\nSkip to main content\nAI in 2025: Building Blocks Firmly in Place\nPublished December 9, 2024\nBy\nDavid Cahn\n2024 was AI’s primordial soup year. In 2025, AI’s foundations are solidifying.\nPublished December 9, 2024\nBy\nDavid Cahn\nLast January, we compared ChatGPT to AI’s “Big Bang” and predicted that 2024 would be AI’s “\nprimordial soup\n” year. The AI ecosystem was abounding with new ideas and potential energy. It was a ripe moment for new entrepreneurs. “There is much potential in the air, and yet it is still amorphous,” we wrote at the time. “Vision is required to convert it into something real, tangible and, ultimately, impactful.”\nToday, the AI ecosystem has hardened. There are now five “finalists” in the\nrace for biggest model\n. Nvidia’s highly anticipated Blackwell chip is shipping\nthis month\n. Data centers, many of which were planned in early 2024, are entering full-on\nbuild mode\n. TSMC is building new fab capacity and Broadcom is working on custom AI chips: the entire\nsupply chain\nhas shifted into high gear. In every industry from healthcare to law to insurance, new AI initiatives are kicking off.\nIf 2024 was the primordial soup year for AI, the building blocks are now firmly in place. AI’s potential is now congealing into something real and tangible—embodied by physical data centers that are rising up all across America from Salem, PA to Round Rock, TX to Mount Pleasant, WI. If 2024 was about new ideas abounding, 2025 will be about sifting through those ideas to see which really work.\nBelow, we offer three predictions for the year ahead:\n1. LLM providers have evolved distinct superpowers—this should lead to incremental differentiation and a contested pecking order in 2025\nIn 2024, the big model race was all about reaching parity with GPT-4. Five companies achieved this objective (or got close enough) and thus became “finalists:” Microsoft/OpenAI, Amazon/Anthropic, Google, Meta and xAI. Others dropped out of the race, most notably, Inflection, Adept and Character.\nTo get to GPT-4 quality, these companies ran roughly the same playbook: Collect as much data as possible, train on as many GPUs as possible and refine the pre-training/post-training architecture to maximize performance. With talent moving fluidly across organizations in 2024, few trade secrets remain.\nAs each player prepares for the next round of LLM scaling—which will likely involve another\n10x increase\nin compute scale—the labs are evolving differentiated superpowers. They have “chosen their weapons,” so to speak, for the battle ahead. In 2025, these distinct strategies should lead to disparate outcomes, with some players pulling ahead and others falling behind.\nGoogle – Vertical Integration:\nGoogle’s advantage going into 2025 is vertical integration. Google is the only player with its own first-class chips: TPUs have a chance to give NVDA GPUs a run for their money in 2025. Google also builds its own data centers, trains its own models and has a very strong internal research team. Unlike Microsoft and Amazon, which have partnered with OpenAI and Anthropic, respectively, Google is going for the prize by owning every part of the value chain.\nOpenAI – Brand:\nWe’ve seen a handful of surveys on unaided awareness of ChatGPT vs. Claude vs. Gemini, and it’s not close. OpenAI has the strongest brand in AI, bar none. This has resulted in the strongest revenue engine among the big AI players, with OpenAI reportedly north of\n$3.6B\nin revenue. If success in AI ends up hinging on consumer mindshare and enterprise distribution, OpenAI may continue to widen the gap between itself and rivals.\nAnthropic – Talent:\n2024 saw a big exodus of research talent from OpenAI, paired with inflows to Anthropic. With Jon Schulman, Durk Kingma and Jan Leike all leaving OpenAI for Anthropic in 2024, Anthropic has been gaining mindshare with research talent. The company also made some big executive hires, adding Instagram co-founder Mike Kreiger as Chief Product Officer. With GPT-3 inventor Dario Amodei at the helm, Anthropic has carved out its position as a favored destination for AI scientists.\nxAI – Data Center Construction:\nWe wrote in our piece on “\nSteel, Servers, and Power\n” about the importance of data center construction to the next phase of the AI race. With xAI bringing on their 100k GPU Colossus cluster\nin record time\n, the company is now the pace setter for data center scaling. The next milestone for xAI and its rivals will be a 200k cluster and then a 300k cluster. If it ends up being true that “scale is all you need,” xAI is well-positioned to continue its rapid ascent.\nMeta – Open Source:\nMeta, which already has strong distribution advantages through Instagram, WhatsApp and Facebook, has chosen to go all-in on open source. Meta is the only big player in the pack taking this approach. Meta’s Llama models have ardent fans and the closed-source vs. open-source debate continues to rage on. If frontier advancements start to slow down, Meta will be well-positioned to leverage its open-source models for rapid dissemination of these capabilities.\nIn the big model race, rigorous execution lies ahead. The competitive landscape and posture of each of the players has solidified. In 2025, we will see which of these strategies prove prescient—and which prove ill-fated.\n2. AI Search is emerging as a killer app—in 2025, it will proliferate\nEver since ChatGPT came out, we’ve all been on the hunt for AI’s killer use case. What persistent new user behaviors will stand the test of time?\nIn 2024, many different applications were tested from AI girlfriends to AI rental assistants to voice agents and AI accountants.\nOne use case that we think will proliferate in 2025 is AI as a search engine. Perplexity has been on a tear since its launch,\nreaching 10M monthly active users\n. OpenAI launched ChatGPT Search in October, an expansion of its existing search-like capabilities.\nThe Wall Street Journal\nran a piece recently headlined “\nGoogling is for Old People\n.” Ironically, this challenge to Google comes just as the company is mired in\nanti-trust litigation\n.\nAI search is a powerful re-invention of a technology that rapidly became the internet’s killer app. Internet search is a navigational technology based on indexing the web. AI search is an informational technology based on LLMs that can read and semantically understand knowledge. For white collar workers, this will be a huge boon.\nAI search may fragment what is currently a monolithic market. It’s possible to imagine a world where every profession has its own specialized AI search engine—analysts and investors now default to Perplexity, lawyers will use platforms like Harvey, and doctors will use solutions like OpenEvidence. Along these lines, one can think of Midjourney as search over the “pixelverse,” Github Copilot as search over the “codeverse,” and Glean as search over the “documentverse.” Unlike in traditional search, AI search can go much deeper semantically, and is therefore an order of magnitude more powerful, resulting in significant incremental productivity gains.\nThe text response as a product surface area is deeper than first meets the eye. Not all text responses are created equal. We think LLMs allow for real product differentiation across multiple dimensions, and that founders will build unique product experiences around these capabilities, targeted at specific customer audiences:\nIntent Extraction:\nTightly matching the response to the user’s intent becomes easier with domain specialization. For example, a doctor and patient asking the same question will want to see different types of responses.\nProprietary Data:\nUnique datasets like case law for lawyers, financial data for analysts or weather data for insurance underwriters will be important in white collar domains. Getting the answer right is table stakes in a business context.\nFormatting:\nHow results are presented to the user, for example how verbose or concise the response is, use of bullets, use of multi-modal content, reference to sources. Accountants tend to digest information differently than journalists, for example.\nInterface Design:\nCode search needs to live in the IDE. Accounting policy search needs to live in your accounting SaaS platform. Semantic search benefits from context around the user’s existing workflow and data. Different domains will require different interfaces.\nNew domain-specific AI search engines will map themselves as tightly as possible onto the “theory of mind” of their target personas. Doctors, lawyers and accountants don’t think alike. As we become experts in a given domain, our patterns for extracting knowledge and making decisions begin to diverge. Doctors confront medical literature, lawyers confront case law, investors confront earnings reports. The way we dissect, analyze and make decisions on this knowledge is different in each domain.\nThere is likely to be a bifurcation between consumer and enterprise. In our capacity as consumers, we all have roughly the same needs, hence the smashing product-market fit of ChatGPT. However, in our capacity as professionals, we have different needs. It is fairly straightforward to imagine that every knowledge worker will have at least two AI search engines they use daily—one for work and one for everything else.\n3. ROI will remain problematic and CapEx will begin to stabilize in 2025\nWe’ve written about\nAI’s $200B question\nand\nAI’s $600B question\n, which explore the tremendous capital expenditure coming out of the Big Tech companies, and the lack of commensurate end-user revenue to derive a payback for these cash outlays.\nGoing into 2024, the Big Tech companies were nervous about AI being a threat to their oligopoly in the cloud business. As we wrote in the “\nGame Theory of AI CapEx\n,” these companies felt they had no choice but to spend aggressively to ensure their continued dominance in an AI future. If they didn’t spend, others would, and they’d fall behind.\nEntering 2025, the picture has changed dramatically. Big Tech companies have their arms locked firmly around the AI revolution. Not only do they control the vast majority of the data centers that power AI, but they own significant equity stakes in the big model companies, and they are among the\nlargest backers\nof new AI startups.\nWith Big Tech feeling more confident, we think 2025 will be a stabilization year for AI CapEx. If 2024 was a scramble to sign deals for land and power, 2025 will be an execution year. Shovels are in the ground, and these companies will be focused on completing their new projects on-time and on-budget. They will then need to sell this installed capacity to customers and work with enterprises to help them achieve success with their new AI capabilities.\nAfter roughly doubling CapEx levels since pre-ChatGPT, we may see some normalization in 2025. The latest CapEx figures released in Q3 suggest that the trendline is already starting to stabilize inside of Microsoft and Google. Amazon and Meta are still ramping, but may reach steady state in early 2025. (While Meta looks flat in the chart below, the company has issued guidance for increased CapEx in Q4).\nSource: Earnings transcripts, public filings\nOligopolistic dynamics are likely to set-in as well. Each of the Big Tech companies follows their rivals closely. If it looks like the industry is on a glide path to a “new normal,” that may be welcome news for all. It would provide further support for a new equilibrium in 2025 vs. continued ratcheting of spend.\nAs new data center capacity comes online in 2025, AI compute prices should continue their epic decline. This is great news for startups and should incentivize net-new innovation. As we’ve pointed out in the past, startups are primarily consumers of compute vs. producers of compute, and so they benefit from overbuilding. The Big Tech companies are effectively creating a subsidy that will accrue to the entire AI ecosystem.\nMany comparisons have been made between the Clouds and the railroad oligopoly of the Gilded Age. If data centers are indeed the rails of the digital economy, then the new AI rails will be securely in place by the end of 2025. The question remains what freight will ride on those rails, and how we can leverage this new technology to create value for customers and end-users.\nHere’s to a year of leveraging AI’s building blocks to create incredible new capabilities that will change people’s lives.\nIf you are building a visionary company in AI, I’d love to hear from you. Please reach out at\ndcahn@sequoiacap.com\nJOIN OUR MAILING LIST\nGet the best stories from the Sequoia community.\nEmail address\nLeave this field empty if you’re human:\nShare\nShare this on Facebook\nShare this on Twitter\nShare this on LinkedIn\nShare this via email\nRelated Topics\n#AI\nAI in 2024: From Big Bang to Primordial Soup\nBy David Cahn\nPerspective\nRead\nAI’s $600B Question\nBy David Cahn\nPerspective\nRead\nGenerative AI’s Act o1\nby Sonya Huang, Pat Grady, and o1\nPerspective\nRead\nThe AI Supply Chain Tug of War\nBy David Cahn\nPerspective\nRead\nBy navigating this website you agree to our cookie policy.\nAccept\nDecline', 'image_urls': [{'url': 'https://www.sequoiacap.com/wp-content/uploads/sites/6/2024/12/AI-in-25.jpg', 'score': 1}], 'title': 'AI in 2025: Building Blocks Firmly in Place | Sequoia Capital'}, {'url': 'https://www.lomitpatel.com/articles/best-ai-startups-to-build-in-2025-opportunities-for-success/', 'raw_content': 'Best AI Startups to Build in 2025: Opportunities for Success - Lomit Patel\nArticles\nBest AI Startups to Build in 2025: Opportunities for Success\nBy\nLomit Patel\nNovember 21, 2024\n6 Mins Read\nShare\nFacebook\nTwitter\nLinkedIn\nEmail\nYou are here:\nHome\n»\nArticles\n»\nBest AI Startups to Build in 2025: Opportunities for Success\nThe artificial intelligence (\nAI\n) boom is far from over, and as we approach 2025, the landscape for the best AI\nstartups\nis promising and competitive. With industries embracing AI-driven solutions, the opportunities to build transformative startups are immense. However, success in this rapidly evolving market requires a keen understanding of where the real opportunities lie.\nHere’s a look at the best types of AI startups poised to thrive in 2025, enriched by my expertise as an AI leader and author of\nLean AI\n, and grounded in key industry trends, emerging needs, and market opportunities.\n1.\nAI for Specialized Industries\nWhile general-purpose AI tools like ChatGPT and DALL-E have captured public attention, the future lies in industry-specific solutions. Healthcare, manufacturing, agriculture, and law enterprises demand AI tools tailored to their unique challenges.\nOpportunities in Specialized AI:\nHealthcare\n: AI for early disease detection, personalized treatment plans, and hospital operational efficiency.\nManufacturing\n: AI-powered predictive maintenance, real-time quality control, and supply chain optimization.\nLegal Tech\n: Tools that can automate contract analysis, legal research, and case\nmanagement\nfor law firms.\nAgriculture\n: AI-driven crop monitoring, irrigation optimization, and predictive analytics for yield forecasting.\nStartups focusing on these verticals and collaborating closely with industry experts to develop actionable solutions are poised to succeed.\n2.\nAI for Sustainability and Climate Tech\nClimate change remains one of humanity’s most pressing challenges, and AI is becoming crucial in addressing it. From renewable energy optimization to carbon tracking, the potential for AI-powered solutions in sustainability is enormous.\nHigh-Impact Areas:\nEnergy Optimization\n: AI systems to manage energy grids, optimize renewable energy usage, and reduce wastage.\nCarbon Footprint Tracking\n: Platforms that help businesses and individuals measure, reduce, and offset their emissions.\nSustainable Agriculture\n: AI tools for precision farming, reducing resource consumption, and improving food security.\nWildlife and Habitat Protection\n: AI-powered monitoring systems to protect biodiversity and manage natural resources.\nGovernments, enterprises, and consumers increasingly prioritize sustainable practices, making this an excellent area for startups.\n3.\nGenerative AI for Business Applications\nGenerative AI isn’t just for creating art or answering questions anymore. Businesses are actively exploring how generative models can streamline operations and boost productivity.\nBusiness-Focused Applications:\nContent Creation\n: AI tools that generate marketing copy, design templates, and sales pitches tailored to specific audiences.\nCode Generation\n: Platforms that help developers create boilerplate code, debug issues, or even architect entire systems.\nHR and Recruitment\n: Tools for automating job descriptions, candidate screening, and personalized onboarding experiences.\nFinancial Analysis\n: AI that generates detailed financial reports, forecasts, and investment strategies based on real-time data.\nThe key to success in this domain is developing tools that integrate seamlessly into existing workflows and deliver measurable ROI.\n4.\nAI for Privacy and Security\nWith the rise of data breaches and regulatory pressures, privacy and security are top priorities for businesses and individuals. AI startups focused on protecting sensitive information will find a growing market.\nPromising Areas in AI Security:\nAI-Powered Cybersecurity\n: Tools that predict, detect, and respond to cyber threats in real-time.\nPrivacy-Preserving AI\n: Federated learning and differential privacy solutions that allow data to be used without compromising individual security.\nIdentity Verification\n: Advanced AI for fraud detection, biometric authentication, and secure transactions.\nRegulatory Compliance\n: Tools to help businesses navigate complex data privacy laws like GDPR and CCPA.\nAs consumers and enterprises demand better protection, startups that offer cutting-edge, user-friendly solutions will stand out.\n5.\nAI for Education and Upskilling\nThe demand for AI-driven educational tools is set to skyrocket as organizations and individuals prioritize continuous learning in an AI-powered world.\nAreas of Focus:\nPersonalized Learning\n: Platforms that adapt content to a learner’s unique pace, style, and goals.\nCorporate Training\n: AI tools for skill assessments, personalized training plans, and employee development programs.\nCoding Education\n: Startups offering tools to teach coding and AI development to kids and professionals alike.\nLanguage Learning\n: Generative AI-based conversational tools for mastering new languages faster.\nAI’s role in education isn’t about replacing teachers but augmenting their efforts and enabling more tailored learning experiences.\n6.\nAI for Collaborative Workflows\nRemote and hybrid work models are here to stay, and AI has a unique opportunity to enhance collaboration, productivity, and employee engagement.\nKey Opportunities:\nIntelligent Project Management\n: AI platforms automate task allocation, track team progress, and predict bottlenecks.\nAI-Powered Meeting Tools\n: Systems that transcribe meetings, summarize discussions, and track actionable insights.\nTeam Analytics\n: Tools that provide insights into employee well-being, productivity patterns, and team dynamics.\nKnowledge Management\n: AI systems that organize company knowledge, making it easier for teams to access and share information.\nStartups that simplify remote work complexities while enhancing collaboration will be indispensable to businesses.\n7.\nAI Infrastructure and Tooling\nBuilding and deploying AI models is complex, and many organizations lack the expertise to do it effectively. Startups providing AI infrastructure and tooling can fill this gap.\nKey Solutions:\nModel Deployment\n: Simplifying the process of taking AI models from development to production.\nAI Monitoring\n: Tools that track model performance, detect biases, and suggest improvements.\nData Annotation\n: AI-assisted labeling tools to speed up the creation of high-quality training datasets.\nLow-Code AI Platforms\n: Solutions enabling non-technical users to build and deploy AI systems.\nBy making AI accessible to more companies, these startups can unlock significant demand.\nHow to Maximize Success\nBuilding an AI startup in 2025 will require more than a good idea. Here are some tips for ensuring your startup has the best chance of success:\nSolve Real Problems\n: Focus on creating tangible value rather than chasing hype.\nUnderstand Your Audience\n: Whether your audience is enterprises, small businesses, or consumers, tailor your solution to their needs.\nBuild for Scalability\n: Design your product to grow with your customer base.\nStay Ahead of Regulations\n: Ensure your AI solutions comply with data privacy and ethical standards.\nPrioritize User Experience\n: Make your AI tools intuitive and easy to use.\nConclusion\nThe\nAI startup\nlandscape in 2025 offers immense opportunities for founders willing to innovate and solve pressing problems. Whether you’re building for specialized industries, sustainability, or business workflows, the key to success lies in understanding market needs, delivering real value, and staying grounded amidst the hype.\nFor aspiring entrepreneurs, the best AI startups to build are those that don’t just ride the wave of innovation but shape its direction. Focus on making an impact, and the rewards will follow.\nSubscribe to my\nLEAN 360 newsletter\nto learn more about startup insights.\nAI\nArtificial Intelligence\nStartups\n1\nAuthor\nLomit Patel\nLomit is a marketing and growth leader with experience scaling hyper-growth startups like Tynker, Roku, TrustedID, Texture, and IMVU. He is also a\xa0renowned public speaker, advisor, Forbes and HackerNoon contributor, and author of "Lean AI," part of the bestselling "The Lean Startup" series by Eric Ries.\nWebsite\nLinkedIn\nRelated Posts\nAI Consulting Tips: Boosting Your Startup’s Success\nMarch 2, 2025\nVC Funding: A Comprehensive Guide for Startup Founders\nMarch 2, 2025\nAI Model Selection: A Guide for Startup Success\nMarch 1, 2025\nCEO Mistakes Lessons: Key Insights for Startup Success\nMarch 1, 2025\nWe use cookies to ensure that we give you the best experience on our website. If you continue to use this site we will assume that you are happy with it.\nOk', 'image_urls': [{'url': 'https://www.lomitpatel.com/wp-content/uploads/2024/11/qtq80-L23vpq.jpeg', 'score': 2}], 'title': 'Best AI Startups to Build in 2025: Opportunities for Success - Lomit Patel'}, {'url': 'https://substack.tech-talk-cto.com/p/introducing-rwkv-an-alternative-to', 'raw_content': 'Introducing RWKV - an alternative to transformers - and why alternatives matter\nTech Talk CTO\nSubscribe\nSign in\nShare this post\nTech Talk CTO\nIntroducing RWKV - an alternative to transformers - and why alternatives matter\nCopy link\nFacebook\nEmail\nNotes\nMore\nIntroducing ...\nIntroducing RWKV - an alternative to transformers - and why alternatives matter\nFor a healthier future in AI\nEugene Cheah\nSep 04, 2023\n1\nShare this post\nTech Talk CTO\nIntroducing RWKV - an alternative to transformers - and why alternatives matter\nCopy link\nFacebook\nEmail\nNotes\nMore\nShare\nThe following is an abstract of some thoughts i had from the RWKV podcast found here:\nhttps://www.latent.space/p/rwkv#details\nWhy Alternatives Matters ?\nTransformer architectures are currently at their peak with the AI revolution of 2023. However, in the rush to adopt them due to their recent success, it\'s easy to ignore alternatives that we can learn from.\nAs engineers, we should not take a one-size-fits-all approach, using the same hammer for every nail. We should find trade-offs in every solution. Failure to do so would trap us within the limitations of one particular platform, while remaining blissfully unaware of all other alternatives. This could potentially hold back development for years.\nThis problem is not unique to AI. It\'s a historical pattern that has repeated itself since ancient times up to the modern day.\nA page from the SQL war history...\nA notable recent example in software development was the trend towards NoSQL when SQL servers started hitting physical limitations. Startups everywhere made the move to NoSQL for "scale" reasons, despite being nowhere near those scales.\nHowever, over time as eventual consistency and NoSQL management overhead emerged, and hardware capabilities made giant leaps in SSD speed and capacity, we\'ve seen a recent trend back to SQL servers for their simplicity and now sufficient scalability for 90%+ of startups.\nDoes this mean SQL is better than NoSQL or vice versa? No, it simply means each technology has preferred use cases with pros/cons and learning points that can cross-pollinate among similar technologies.\nI hope you view this article as not an attack on transformers, but a healthy appreciation on alternatives. With that, lets get on to the main topic\nWhat is the biggest pain point for existing transformer architecture?\nGenerally this covers compute, context length, datasets and alignment. For this discussion, we\'ll focus on compute and context length:\nQuadratic computational costs due to O(N^2) increase per token used/generated. This makes context sizes >100k incredibly expensive. Which impacts inference and training.\nCurrent GPU shortage exacerbates this issue.\nContext size limits attention, heavily restricting "smart agent" use cases (like\nsmol-dev\n), forcing workarounds. Larger contexts need fewer workarounds.\nSo how do we solve this?\nIntroducing RWKV - a linear transformer / modern large scale RNN\nThe following summarises the RWKV paper at a high level:\nhere\nFor a deeper technical dive on RWKV architecture, see the:\nwiki here\nRWKV\n, along with\nMicrosoft RetNet\n, are among the first of a new class called\n"Linear Transformers"\n.\nIt tackles the above 3 limitations directly by supporting the following\nLinear computational cost regardless of context size.\nLower requirements allow reasonable token/sec output on CPU (especially ARM) in RNN mode.\nNo hard context size limit as an RNN. Any limits in docs are guidelines - you can finetune beyond them.\nAs we continue to scale up AI models, to large context sizes. From 100k and beyond. The quadratic computational costs starts to exponentially increase.\nLinear Transformers, however instead of abandoning the Recurrent Neural Network architecture and their bottlenecks which forced them to be replaced by transformers.\nTook lessons learnt from making transformers scalable, and re-engineered RNN\'s to work similar to transformers, and remove all those bottleneck.\nBringing them back into the race with transformers, in terms of training speeds. Allowing them to both operate efficiently at O(N) cost, while scaling past a billion parameters in training. All while maintaining similar performance levels.\nAs you scale quadratically vs linear, you will hit over 10x at 2k token count & over a 100x at 100k token length.\nAt 14B parameters, RWKV is the largest open-source linear transformer, on par with GPT-NeoX and others on similar datasets (e.g. The Pile).\nBut what does this mean, in simpler terms?\nPros\n10x++ cheaper inference/training than transformers at large context sizes\nCan run slowly on very limited hardware in RNN mode\nSimilar performance to transformers on same datasets\nNo technical context size limit as RNN (infinite context!)\nCons\nSliding window problem, with lossy memory past a certain point\nNot proven to scale beyond 14B parameters yet\nLess optimised and adopted than transformers\nSo while RWKV isn\'t yet at 60B+ parameter scales like LLaMA2, with the right support/resources it has potential to get there at lower cost and larger contexts. Especially as expert models trend towards smaller and efficient.\nConsider it if efficiency matters for your use case. But it\'s not the final solution - healthy alternatives are still key.\nAlso one last thing i forget to mentioned:\nLinear Transformers typically do not use classic Transformer attention, but an approximate equivalent, meaning ...\nAttention is Not All You Need\nOther alternatives and its benefits we should probably learn from\nDiffusion Models\n: Slow to train for text, but extremely resilient to multi-epoch training. Figuring out why could help mitigate\nthe token crisis\nGenerative Adversarial Networks / Agents\n: techniques could be used to train desired skillsets, to a specific goal without datasets. Even for text based models\nThanks for reading Tech Talk CTO! Subscribe for free to receive new posts and support my work.\nSubscribe\nDisclosure:\nI am a code contributor to the RWKV project, and an active member in the community.\nHowever it does not mean I view RWKV as the final answer, even if in the future where "Linear Transformers" beat out traditional "Transformer" networks in the future, research into alternatives is still important for healthy ecosystem development.\nI strongly believe there is no such thing as "one architecture to rule them all"\nAdditionally, i am aware there has since been developments like TransformerXL to more efficiently scale transformers, somewhere between quadratic cost, and linear cost. However with very limited known implementation of this method in public, it is hard for me to evaluate its pros and cons.\n1\nShare this post\nTech Talk CTO\nIntroducing RWKV - an alternative to transformers - and why alternatives matter\nCopy link\nFacebook\nEmail\nNotes\nMore\nShare\nPrevious\nDiscussion about this post\nComments\nRestacks\nTop\nLatest\nDiscussions\nNo posts\nReady for more?\nSubscribe\nShare\nCopy link\nFacebook\nEmail\nNotes\nMore\nThis site requires JavaScript to run correctly. Please\nturn on JavaScript\nor unblock scripts', 'image_urls': [{'url': 'https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84718161-3d73-4e43-97b9-ae36df5a5172_1237x690.png', 'score': 1}], 'title': 'Introducing RWKV - an alternative to transformers - and why alternatives matter'}, {'url': 'https://www.forbes.com/sites/joannechen/2024/07/23/whats-next-after-transformers/', 'raw_content': "What's Next After Transformers\nWhat's Next After Transformers\nBy\nJoanne Chen\nFollow\nSave Article\nComment\nInnovation\nVenture Capital\nWhat's Next After Transformers\nBy\nJoanne Chen\n, Contributor.\nJoanne Chen is a General Partner at Foundation Capital.\nFollow Author\nJul 23, 2024, 06:55pm EDT\nSave Article\nComment\nI talk with Recursal AI founder Eugene Cheah about RWKV, a new architecture that\nThis essay is a part of my series, “AI in the Real World,” where I talk with leading AI researchers about their groundbreaking work and how it's being applied in real businesses today. You can check out previous conversations in the series\nhere\n.\nI recently spoke with Eugene Cheah, a builder who’s working to democratize AI by tackling some of the core constraints of transformers. The backbone of powerhouse models like GPT and Claude, transformers have fueled the generative AI boom. But they're not without drawbacks.\nEnter RWKV (Receptance Weighted Key Value), an open-source architecture that Eugene and his team at Recursal AI are commercializing for enterprise use. Their goal is ambitious but clear: make AI more cost-effective, scalable, and universally accessible, regardless of a user's native language and access to compute.\nEugene's journey from nurturing RWKV's open-source ecosystem to founding Recursal AI reflects the potential he sees in this technology. In our conversation, he explains the technical challenges facing transformers and details how RWKV aims to overcome them. I left with a compelling picture of what a more democratic future for AI might look like – and what it would take to get there.\nMORE FROM\nFORBES ADVISOR\nBest High-Yield Savings Accounts Of 2024\nBy\nKevin Payne\n,\nContributor\nBest 5% Interest Savings Accounts of 2024\nBy\nCassidy Horton\n,\nContributor\nHere are my notes.\nIs attention really\nall\nyou need?\nIntroduced in the 2017 paper\n“Attention is All You Need”\nby a group of Google Brain researchers, transformers are a form of deep learning architecture designed for natural language processing (NLP). One of their key innovations is self-attention: a mechanism that captures relationships between words regardless of their position in a sequence. This breakthrough has led to numerous advanced models, including BERT, GPT, and Claude.\nYet, despite their power, transformers face significant hurdles in cost and scalability. For each token (roughly equivalent to short word or a part of a longer word) processed, transformers essentially recalculate all their calculations. This leads to quadratic scaling costs as the context length increases. In other words, doubling the input length quadruples the amount of compute required.\nThis inefficiency translates into enormous demands on compute. While exact figures are hard to come by, OpenAI reportedly uses over 300 Azure data centers just to serve 10% of the English-speaking market. Running transformers in production can cost hundreds of thousands or even millions of dollars per month, depending on their scale and usage.\nDespite these steep scaling costs, transformers maintain their dominant position in the AI ecosystem. Stakeholders across all levels of the AI stack have invested substantial resources to build the infrastructure necessary to run these models in production. This investment has created a form of technological lock-in, resulting in strong resistance to change.\nAs my colleague Jaya\nexplained\n: “The inertia around transformer architectures is real. Unless a new company bets big, we'll likely see incremental improvements rather than architectural revolutions. This is partly due to the massive investment in optimizing transformers at every level, from chip design to software frameworks. Breaking this inertia would require not just a superior architecture, but a willingness to rebuild the entire AI infrastructure stack.”\nFaced with such a herculean lift, most stakeholders opt for the familiar. Of course, this status quo is not set in stone. Eugene and the RWKV community certainly don’t seem to think so.\nRWKV: a potential alternative?\nInstead of the all-to-all comparisons of transformers, RWKV uses a linear attention mechanism that's applied sequentially. By maintaining a fixed state between tokens, RWKV achieves more efficient processing with linear compute costs. Eugene claims that this efficiency makes RWKV 10 to 100 times cheaper to run than transformers, especially for longer sequences.\nRWKV’s benefits extend beyond compute efficiency. Its recurrent architecture means it only needs to store and update a single hidden state vector for each token. Compare this to transformers, which must juggle attention scores and intermediate representations for every possible token pair. The memory savings here could be substantial.\nRWKV’s performance compared to transformers remains a topic of active research and debate in the AI community. Its approach, while innovative, comes with its own set of challenges. The token relationships it builds, while more efficient to compute, aren't as rich as those in transformers. This can lead to difficulties with long-range dependencies and information retrieval. Moreover, RWKV is more sensitive to the order of input tokens, meaning small changes in how a prompt is structured can significantly alter the model’s output.\nPromising early signs\nRWKV isn't just a concept on paper: it’s being used in real applications today. Eugene cites a company processing over five million messages daily using RWKV for content moderation, achieving substantial cost savings compared to transformer-based alternatives.\nBeyond cost-cutting, RWKV also promises to level the linguistic playing field. Its sequential processing method reduces the English-centric bias in many transformer-based models, which stems from their training data and tokenization methods, as well as the benchmarks by which they’re judged. Currently, RWKV models can handle over 100 languages with high proficiency: a significant step toward more inclusive AI.\nWhile direct comparisons are challenging due to differences in training data, the early results are impressive. Eugene reports that RWKV's 7B parameter model (trained on 1.7 trillion tokens) matches or outperforms Meta's LLaMA 2 (trained on 2 trillion tokens) across a variety of benchmarks, particularly in non-English evals. These results hint at superior scaling properties compared to transformers, though more research is needed to confirm this conclusively.\nBeyond encouraging evals, RWKV also has the potential to break us out of the “architecture inertia” described by my partner Jaya. Eugene explains that RWKV’s design allows for relatively simple integration into existing AI infrastructures. Training pipelines designed for transformers can be adapted for RWKV with minimal tweaks. Preprocessing steps like text normalization, tokenization, and batching also remain largely unchanged.\nThe primary adjustment needed when using RWKV comes at inference time. Unlike transformers, which handle each input separately, RWKV manages hidden states across time steps. To accommodate this, developers have to modify how hidden states are managed and passed through the model during inference. While this requires some changes to inference code, it’s a relatively manageable adaptation—more of a shift in approach than a complete overhaul.\nImplications for the AI field\nBy improving efficiency and reducing costs, RWKV has the potential to broaden access to AI. Here are a few of the implications that Eugene highlighted:\n1. Unleashing innovation through lower costs\nCurrent transformer-based models pose prohibitive costs, particularly in developing economies. This financial hurdle stifles experimentation, limits product development, and constrains the growth of AI-powered businesses. By providing a more cost-effective alternative, RWKV could level the playing field, allowing a more diverse range of ideas and innovations to flourish.\nThis democratization extends to academia as well. The exponential growth in compute costs driven by transformers has hampered research efforts, particularly in regions with limited resources. By lowering these financial barriers, RWKV could catalyze more diverse contributions to AI research from top universities in India, China, and Latin America, for instance.\n2. Breaking language barriers\nLess than 20% of the world speaks English, yet, as discussed above, most transformer-based models are biased toward it . This limits users and applications, particularly in regions with multiple dialects and linguistic nuances.\nRWKV’s multilingual strength could be used to build products that solve these local problems. The Eagle 7B model, a specific implementation of RWKV,\nhas shown\nimpressive results on multilingual benchmarks, making it a potential contender for local NLP tasks. Eugene shared an example of an RWKV-powered content moderation tool capable of detecting bullying across multiple languages, illustrating the potential for more inclusive and culturally attuned AI applications.\n3. Enhancing AI agent capabilities\nAs we venture further into the realm of\nAI agents\nand\nmulti-agent systems\n, the efficiency of token generation becomes increasingly crucial. As agents converse, collaborate, and call external tools, these complex systems often generate\nthousands of tokens\nbefore returning an output to the user. RWKV's more efficient architecture could significantly enhance the capabilities of these agentic systems.\nThis efficiency gain isn't just about speed; it's about expanding the scope of what's possible. Faster token generation could allow for more complex reasoning, longer-term planning, and more nuanced interactions between AI agents.\n4. Decentralizing AI\nThe concentration of AI power in the hands of a few tech giants has raised valid concerns about access and control. Many enterprises aspire to run AI models within their own environments, yet this goal often remains out of reach. RWKV's efficiency could make this aspiration a reality, allowing for a more decentralized AI ecosystem.\nWhat’s next for RWKV?\nWhile the potential of RWKV is clear, its journey from promising technology to industry standard is far from guaranteed.\nCurrently, Eugene is focused on raising capital and securing the substantial compute power needed for larger training runs. He aims to keep pushing the boundaries of RWKV's model sizes and performance, and potentially expand into multimodal capabilities—combining text, audio, and vision into unified models. In parallel, the RWKV community is working on improving the quality and diversity of training datasets, with a particular emphasis on non-English languages.\nEugene is also excited about exploring other alternative architectures, such as diffusion models for text generation. His openness reflects a broader trend in the AI community: a recognition that the path forward requires novel ideas for model design.\nWhile the long-term viability of these new architectures remains to be seen, democratizing AI is certainly a worthy goal. Lower costs, better multilingual capabilities, and easier deployment could enable AI to be used in a much wider range of applications and contexts, accelerating the pace of innovation in the field.\nFor founders interested in exploring these possibilities, Eugene recommends the\nRWKV Discord\nand\nwiki\n, as well as the\nEleutherAI Discord\n.\nFollow me on\nTwitter\nor\nLinkedIn\n.\nEditorial Standards\nForbes Accolades\nLOADING VIDEO PLAYER...\nFORBES’ FEATURED Video", 'image_urls': [], 'title': "What's Next After Transformers"}, {'url': 'https://www.impactlab.com/2024/10/04/liquid-ai-unveils-groundbreaking-foundation-models-challenging-transformer-based-ai/', 'raw_content': 'Liquid AI Unveils Groundbreaking Foundation Models, Challenging Transformer-Based AI – Impact Lab\nSkip to content\nAI\nLiquid AI, a startup co-founded by former MIT researchers from the Computer Science and Artificial Intelligence Laboratory (CSAIL), has introduced its first multimodal AI models, the “Liquid Foundation Models (LFMs).” These models represent a bold departure from the transformer architecture that has dominated AI development since the release of the 2017 paper “Attention Is All You Need.”\nUnlike the current wave of generative AI models built on the transformer architecture, Liquid AI aims to develop foundation models from “first principles,” taking an engineering approach akin to building engines, cars, or airplanes. This fundamental shift has led to models that outperform transformer-based alternatives of similar size, such as Meta’s Llama 3.1-8B and Microsoft’s Phi-3.5 3.8B.\nLiquid AI’s LFMs come in three variants:\nLFM 1.3B\n(smallest)\nLFM 3B\nLFM 40B MoE\n(largest, a “Mixture-of-Experts” model similar to Mistral’s Mixtral)\nThe “B” in these models’ names refers to the number of parameters, with higher parameter counts generally resulting in broader capabilities across various tasks. Liquid AI reports that its smallest model, the LFM 1.3B, already surpasses Meta’s Llama 3.2-1.2B and Microsoft’s Phi-1.5 on benchmarks like the Massive Multitask Language Understanding (MMLU) test, which covers 57 science, tech, engineering, and math (STEM) problems. This is the first time a non-transformer-based architecture has outperformed traditional models.\nIn addition to excelling in benchmarks, Liquid AI’s LFMs are highly memory efficient. For example, the LFM-3B model requires only 16 GB of memory, compared to the 48 GB needed by Meta’s Llama-3.2-3B model. This efficiency makes the LFMs ideal for a wide range of applications, from enterprise-level tasks in financial services and biotechnology to deployment on edge devices.\nMaxime Labonne, Liquid AI’s Head of Post-Training, celebrated the release of the LFMs on social media, calling them the “proudest release of my career.” Labonne emphasized that the key advantage of LFMs is their ability to deliver superior performance while consuming significantly less memory than their transformer-based counterparts.\nLiquid AI’s models are designed to process various types of sequential data, including audio, video, text, time series, and signals. This multimodal capability enables them to address complex challenges across diverse industries such as biotechnology, financial services, and consumer electronics. Built on computational principles rooted in dynamical systems, signal processing, and numerical linear algebra, the LFMs can efficiently handle up to 1 million tokens while minimizing memory usage, even as token length increases.\nThe LFM-3B model, for instance, maintains a smaller memory footprint than models like Google’s Gemma-2 and Microsoft’s Phi-3, making it particularly effective for long-context processing tasks such as document analysis or chatbot applications.\nLiquid AI’s models aren’t open source but are accessible through the company’s inference playground, Lambda Chat, and Perplexity AI. Liquid AI has optimized these models for deployment on various hardware platforms, including NVIDIA, AMD, Apple, Qualcomm, and Cerebras, allowing for broad compatibility across industries.\nAlthough the models are still in a preview phase, Liquid AI invites early adopters and developers to test them and provide feedback. Labonne acknowledged that while the models are not perfect, the feedback will help the team refine the models ahead of their full launch on October 23, 2024, at MIT’s Kresge Auditorium in Cambridge, MA. The event will include technical discussions, and Liquid AI plans to release a series of blog posts detailing the technology behind its models.\nAs part of its commitment to transparency, Liquid AI is encouraging red-teaming efforts to identify weaknesses and improve future iterations. With the introduction of the Liquid Foundation Models, Liquid AI is positioning itself as a key player in the foundation model landscape, offering a compelling alternative to the transformer-based architectures that currently dominate the space.\nBy combining state-of-the-art performance with remarkable memory efficiency, Liquid AI is setting the stage for a new era of AI development.\nBy Impact Lab\nSearch for:\nCategories\nCategories\nSelect Category\n2019 CES\n2019 Predictions\n2020 Predictions\n2021 Predictions\n2022 CES\n2022 predictions\n2023 CES\n3D Printer\n6G\nAdvertising\nAgriculture\nAI\nAirbnb\nAirbus\nAlternative Transportation\nAlzheimer’s Disease\nAmazon.com\nAnalysis\nAnimals\nApp\nApple\nArchitecture\nArt\nArtificial Intelligence\nAtomic Clock\nAugmented Reality\nAutomation\nAutomobiles\nAviation\nAward Winner\nBaby Gadgets\nBanking\nBatteries\nBattery\nBeauty\nBeer\nbicycle\nBig Data\nBig Problems\nBill Gates\nBiotech\nBirth\nBitcoin\nBlockchain\nbluetooth\nbody antenna\nBoeing\nBotnet\nBrain\nbrain hacking\nbrain malware\nbrain-computer interfaces\nbrains\nBreakthrough Thinking\nBusiness\nCamping\nCancer\nCES 2018\nCES 2020\nCES 2021\nChildren\nChina\nCIA\nCinema\nCitibank\nCity Planning\nClimate Change\nClothing\nCo Working\nCoding\nCoding Schools\ncommunication\nComputer Security\nCooking\nCoronavirus\nCorporate Manipulation\nCoworking\nCrazy Photos\nCrazy Stuff\nCredit\nCrime\nCrime Prevention\nCrypto Currency\nCrypto-Technology\nCulture\nCurrent Events\ncutting edge\nDARPA\nDating\nDaVinci Coders\nDaVinci Institute\nDaVinci Inventor Showcase\nDDoS\nDIY\nDNA\nDriverless cars\nDriverless vehicles\nDrone\ndrones\nEcological Products\nEconomy\nEducation\nElectric Automobile\nElectric Vehicles\nElon Musk\nEmployment\nEnergy\nEngineering\nEntertainment\nEnvironment\nfacebook\nFamous Inventor\nFarming\nFarms\nFashion\nFilm\nFilms\nFinance\nFood\nFord Motor Company\nFuturati Podcast\nFuture\nFuturist\nGame Development\nGames\nGenes\nGenetics\nGhost Children\nGlobal Warming\nGlobalism\nGoogle\ngovernment\nGreat New Product\nGreat Videos\nGreen Friendly\nHackers\nHacking\nHealth\nHealth & Fitness\nHealthcare\nHigher Education\nHistorical Perspectives\nHome Technology\nHot Issues\nHousing\nHuman Behavior\nHumor\nHyperloop\nIBM\nIBM Watson\nIdeas\nInsects\nInsurance\nIntellectual Property\nIntelligence\nInternet\nInternet of Things\nInventions\nJet\nLatest News\nLatest Trend\nLaw Enforcement\nLED\nLegal Issues\nLegalized marijuana\nLife Skills\nLifestyle\nMachine Learning\nMarketing\nMass Transit\nMedical Breakthrough\nMedicine\nMemory\nMetaverse\nMicrosoft\nMilitary\nmilitary drones\nmobile apps\nmobile technology\nMoney Talk\nMovies\nMusic\nNanotechnology\nNASA\nNetflix\nNew Discoveries\nNew Inventions\nnew technology\nNew Viewpoints\nParenting\nPatents\nPeople Making a Difference\nPhoto Perspectives\nPlant Life\nprivacy\nProgramming\nquantum computing\nRacing\nRecord Breaker\nRecycling\nReport\nRobotics\nRobots\nScience & Technology News\nScience Fiction\nSealife\nsecurity\nSegway\nSelf-driving Cars\nShopping\nSocial Media\nSoftware Development\nSolar Energy\nSolar Power\nSpace\nSpace Flight\nSpaceX\nSpirituality\nsports\nStar Trek\nStar Wars\nStartup\nStem cells\nsubliminal messages\nTechnological Unemployment\nTerrorism\nTesla\nTextiles\nTiny House\nTom Frey\ntop 10\nTop 25 Inventions of 2017\nTourism\nTransportation\nTravel\nTravel\nTrending\nTwitter\nUber\nUncategorized\nUnited Parcel Service\nUpcoming Events\nUPS\nVenture Capital\nVideo\nVideo Games\nVirtual Reality\nVolvo\nVR\nWeapons\nWearables\nWeather\nWi-Fi\nWind Power\nwomen\nYouTube\nRecent Posts\nDubai Partners with The Boring Company to Create a High-Speed Tunnel Network for a Walkable City\nVagus Nerve Stimulation: A Promising Approach to Combat Cognitive Decline iN Alzheimer’s\nNew Method Breaks Down Plastics into Reusable Monomers, Offering Hope for Better Recycling\nHistoric Open-Heart Surgery Performed Mid-Delivery on Newborn in New York\nInnovative Timber-Cardboard Panels Could Revolutionize Temporary Housing for Disaster Relief\nThe AirWing: A Groundbreaking Wind-Powered Solution to Clean Up Shipping Emissions\nChinese Scientists Unveil World’s First Two-Way Adaptive Brain-Computer Interface, Ushering in a New Era of BCI Technology\nA New Approach to AI Learning: Torque Clustering Mimics Natural Intelligence\nComposite Metal Foam: A Breakthrough Material Ready for Mass Production\nHumanoid Robotics Startup Unveils Next-Gen HMND 01, Paving the Way for Human-Robot Collaboration\nNew Carbon Material Surpasses Graphene in Toughness, Resists Cracking\nJapan’s Renewable Energy Leap: Proteus Marine Unveils First Megawatt-Scale Tidal Turbine\nDostarlimab’s Breakthrough Results Offer Hope for Rectal Cancer Patients, Fast-Tracking Path to Approval\nPOSTECH’s Breakthrough in Battery Technology Could Revolutionize Electric Vehicle Efficiency\nWandercraft Launches Clinical Trial for Personal Exoskeleton to Boost Mobility for Individuals with Spinal Cord Injuries\nRecent Posts on FuturistSpeaker.com\nThe Canyon Ferry Disaster – How a Single Event Can Reshape a Nation\nFebruary 20, 2025\nPrint Me a Cure: The Coming Revolution of 3D-printed Polypills\nFebruary 6, 2025\nThe Opposite of War is Not Peace\nJanuary 23, 2025\nThe Turing Test for Humanoid Robots: Changing an Infant’s Dirty Diaper\nJanuary 9, 2025\nSkipping College: The New Playbook for Successful Careers Without College\nDecember 26, 2024\nReimagining Recreation: A Blueprint for the Municipal Tournament Center\nDecember 12, 2024\nThe Evolution of Robots: The Blurring Lines Between People and Machines\nNovember 26, 2024\nShould Robots Have the Right to Defend Themselves?\nNovember 14, 2024\nWill Robots Replace the Kids We’re Not Having?\nOctober 31, 2024\nEven Cantankerous Old Men Need a Buddy Bot\nOctober 17, 2024\nArchives\nArchives\nSelect Month\nFebruary 2025\nJanuary 2025\nDecember 2024\nNovember 2024\nOctober 2024\nSeptember 2024\nAugust 2024\nJuly 2024\nJune 2024\nMay 2024\nApril 2024\nMarch 2024\nFebruary 2024\nJanuary 2024\nDecember 2023\nNovember 2023\nOctober 2023\nSeptember 2023\nAugust 2023\nJuly 2023\nJune 2023\nMay 2023\nApril 2023\nMarch 2023\nFebruary 2023\nJanuary 2023\nDecember 2022\nNovember 2022\nOctober 2022\nSeptember 2022\nAugust 2022\nJuly 2022\nJune 2022\nMay 2022\nApril 2022\nMarch 2022\nFebruary 2022\nJanuary 2022\nDecember 2021\nNovember 2021\nOctober 2021\nSeptember 2021\nAugust 2021\nJuly 2021\nJune 2021\nMay 2021\nApril 2021\nMarch 2021\nFebruary 2021\nJanuary 2021\nDecember 2020\nNovember 2020\nOctober 2020\nSeptember 2020\nAugust 2020\nJuly 2020\nJune 2020\nMay 2020\nApril 2020\nMarch 2020\nFebruary 2020\nJanuary 2020\nDecember 2019\nNovember 2019\nOctober 2019\nSeptember 2019\nAugust 2019\nJuly 2019\nJune 2019\nMay 2019\nApril 2019\nMarch 2019\nFebruary 2019\nJanuary 2019\nDecember 2018\nNovember 2018\nOctober 2018\nSeptember 2018\nAugust 2018\nJuly 2018\nJune 2018\nMay 2018\nApril 2018\nMarch 2018\nFebruary 2018\nJanuary 2018\nDecember 2017\nNovember 2017\nOctober 2017\nSeptember 2017\nAugust 2017\nJuly 2017\nJune 2017\nMay 2017\nApril 2017\nMarch 2017\nFebruary 2017\nJanuary 2017\nDecember 2016\nNovember 2016\nOctober 2016\nSeptember 2016\nAugust 2016\nJuly 2016\nJune 2016\nMay 2016\nApril 2016\nMarch 2016\nFebruary 2016\nJanuary 2016\nDecember 2015\nNovember 2015\nOctober 2015\nSeptember 2015\nAugust 2015\nJuly 2015\nJune 2015\nMay 2015\nApril 2015\nMarch 2015\nFebruary 2015\nJanuary 2015\nDecember 2014\nNovember 2014\nOctober 2014\nSeptember 2014\nAugust 2014\nJuly 2014\nJune 2014\nMay 2014\nApril 2014\nMarch 2014\nFebruary 2014\nJanuary 2014\nDecember 2013\nNovember 2013\nOctober 2013\nSeptember 2013\nAugust 2013\nJuly 2013\nJune 2013\nMay 2013\nApril 2013\nMarch 2013\nFebruary 2013\nJanuary 2013\nDecember 2012\nNovember 2012\nOctober 2012\nSeptember 2012\nAugust 2012\nJuly 2012\nJune 2012\nMay 2012\nApril 2012\nMarch 2012\nFebruary 2012\nJanuary 2012\nDecember 2011\nNovember 2011\nOctober 2011\nSeptember 2011\nAugust 2011\nJuly 2011\nJune 2011\nMay 2011\nApril 2011\nMarch 2011\nFebruary 2011\nJanuary 2011\nDiscover the Hidden Patterns of Tomorrow with Futurist Thomas Frey\nUnlock Your Potential, Ignite Your Success.\nBy delving into the futuring techniques of Futurist Thomas Frey,\nyou’ll embark on an enlightening journey.\nLearn More about this exciting program.', 'image_urls': [], 'title': 'Liquid AI Unveils Groundbreaking Foundation Models, Challenging Transformer-Based AI – Impact Lab'}, {'url': 'https://medium.com/@digvijay.qi/alternatives-to-transformer-based-architectures-3f41faeaacab', 'raw_content': 'Alternatives to Transformer based Architectures | by Digvijay Y | Medium\nOpen in app\nSign up\nSign in\nWrite\nSign up\nSign in\nAlternatives to Transformer based Architectures\nDigvijay Y\n·\nFollow\n2 min read\n·\nFeb 12, 2024\n--\n1\nListen\nShare\nTransformers have revolutionized various AI fields, but research doesn’t stop there. Here are some promising alternatives and potential challengers to the Transformer architecture:\nFocus on attention mechanism:\nRecurrent Neural Networks (RNNs):\nThough computationally expensive, RNNs still find use in specific tasks where sequential context is crucial, like language modeling.\nConvolutional Neural Networks (CNNs):\nWhile primarily used for images, recent adaptations like ConvTransformers demonstrate potential for other domains.\nSparse Attention:\nAttention in Transformers can be computationally expensive. Methods like Sparse Attention and Selective Attention aim to make it more efficient while retaining accuracy.\nBeyond Attention:\nPermutation Equivariant Architectures:\nThese models excel at tasks with inherent order-dependent structures, like protein folding or graph problems, where Transformers might struggle.\nLiquid Neural Networks:\nInspired by physics, these networks use continuous-time dynamics and offer potential for efficient learning and adaptation.\nMeta-Learning and Few-Shot Learning:\nThese approaches tackle learning new tasks with minimal data, potentially surpassing standard training paradigms used in Transformers.\nHybrid Approaches:\nTransformer-CNN hybrids:\nCombining strengths of both architectures for tasks like image captioning or visual question answering.\nTransformer-RNN hybrids:\nLeveraging RNNs for sequential aspects while benefiting from Transformer’s parallel processing for longer sequences.\nThe Next Horizon:\nQuantum Machine Learning:\nWhile still in its nascent stages, quantum computing holds potential for revolutionizing AI, potentially offering architectures beyond current paradigms.\nBrain-inspired models:\nUnderstanding the human brain’s learning mechanisms could lead to entirely new AI architectures with superior performance and efficiency.\nIt’s important to note that no single alternative might universally replace Transformers. Different problems and tasks might benefit from different architectures, and research continues to explore and develop various approaches. The future of AI likely lies in a diverse ecosystem of algorithms, each serving specific purposes and pushing the boundaries of what’s possible.\nMachine Learning\nTransformers\nMachine Learning Models\nMl Architectures\nFollow\nWritten by\nDigvijay Y\n14 Followers\n·\n2 Following\nFollow\nResponses (\n1\n)\nSee all responses\nHelp\nStatus\nAbout\nCareers\nPress\nBlog\nPrivacy\nTerms\nText to speech\nTeams', 'image_urls': [], 'title': 'Alternatives to Transformer based Architectures | by Digvijay Y | Medium'}, {'url': 'https://venturebeat.com/ai/mit-spinoff-liquid-debuts-non-transformer-ai-models-and-theyre-already-state-of-the-art/', 'raw_content': "MIT spinoff Liquid debuts small, efficient non-transformer AI models | VentureBeat\nSkip to main content\nJoin our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage.\nLearn More\nLiquid AI\n, a startup co-founded by former researchers from the Massachusetts Institute of Technology (MIT)’s Computer Science and Artificial Intelligence Laboratory (CSAIL), has announced the\ndebut of its first multimodal AI models\n: the “Liquid Foundation Models (LFMs).”\nUnlike most others of the current generative AI wave, these models are not based around the transformer architecture outlined in the\nseminal 2017 paper “Attention Is All You Need.”\nInstead, Liquid states that its goal “is to explore ways to build foundation models beyond Generative Pre-trained Transformers (GPTs)” and with the new LFMs, specifically building from “first principles…the same way engineers built engines, cars, and airplanes.”\nIt seems they’ve done just that — as the new LFM models already boast superior performance to other transformer-based ones of comparable size such as Meta’s Llama 3.1-8B and Microsoft’s Phi-3.5 3.8B.\nLiquid’s LFMs currently come in three different sizes and variants:\nLFM 1.3B (smallest)\nLFM 3B\nLFM 40B MoE (largest, a “Mixture-of-Experts” model similar to Mistral’s Mixtral)\nThe “B” in their name stands for billion and refers the number of parameters — or settings — that govern the model’s information processing, analysis, and output generation. Generally, models with a higher number of parameters are more capable across a wider range of tasks.\nAlready, Liquid AI says the LFM 1.3B version outperforms\nMeta’s new Llama 3.2-1.2B\nand\nMicrosoft’s Phi-1.5\non many leading third-party benchmarks including the popular Massive Multitask Language Understanding (MMLU) consisting of 57 problems across science, tech, engineering and math (STEM) fields, “the first time a non-GPT architecture significantly outperforms transformer-based models.”\nAll three are designed to offer state-of-the-art performance while optimizing for memory efficiency, with Liquid’s LFM-3B requiring only 16 GB of memory compared to the more than 48 GB required by Meta’s Llama-3.2-3B model (shown in the chart above).\nMaxime Labonne, Head of Post-Training at Liquid AI,\ntook to his account on X\nto say the LFMs were “the proudest release of my career :)” and to clarify that the core advantage of LFMs: their ability to outperform transformer-based models while using significantly less memory.\nThis is the proudest release of my career :)\nAt\n@LiquidAI_\n, we're launching three LLMs (1B, 3B, 40B MoE) with SOTA performance, based on a custom architecture.\nMinimal memory footprint & efficient inference bring long context tasks to edge devices for the first time!\npic.twitter.com/v9DelExyTa\n— Maxime Labonne (@maximelabonne)\nSeptember 30, 2024\nThe models are engineered to be competitive not only on raw performance benchmarks but also in terms of operational efficiency, making them ideal for a variety of use cases, from enterprise-level applications specifically in the fields of financial services, biotechnology, and consumer electronics, to deployment on edge devices.\nHowever, importantly for prospective users and customers, the models are not open source. Instead, users will need to access them through\nLiquid’s inference playground\n,\nLambda Chat\n, or\nPerplexity AI\n.\nHow Liquid is going ‘beyond’ the generative pre-trained transformer (GPT)\nIn this case, Liquid says it used a blend of “computational units deeply rooted in the theory of dynamical systems, signal processing, and numerical linear algebra,” and that the result is “general-purpose AI models that can be used to model any kind of sequential data, including video, audio, text, time series, and signals” to train its new LFMs.\nLast year,\nVentureBeat covered more about Liquid’s approach\nto training post-transformer AI models, noting at the time that it was using Liquid Neural Networks (LNNs), an architecture developer at CSAIL that seeks to make the artificial “neurons” or nodes for transforming data, more efficient and adaptable.\nUnlike traditional deep learning models, which require thousands of neurons to perform complex tasks, LNNs demonstrated that fewer neurons—combined with innovative mathematical formulations—could achieve the same results.\nLiquid AI’s new models retain the core benefits of this adaptability, allowing for real-time adjustments during inference without the computational overhead associated with traditional models, handling up to 1 million tokens efficiently, while keeping memory usage to a minimum.\nA chart from the Liquid blog shows that the LFM-3B model, for instance, outperforms popular models like Google’s Gemma-2, Microsoft’s Phi-3, and Meta’s Llama-3.2 in terms of inference memory footprint, especially as token length scales.\nWhile other models experience a sharp increase in memory usage for long-context processing, LFM-3B maintains a significantly smaller footprint, making it highly suitable for applications requiring large volumes of sequential data processing, such as document analysis or chatbots.\nLiquid AI has built its foundation models to be versatile across multiple data modalities, including audio, video, and text.\nWith this multimodal capability, Liquid aims to address a wide range of industry-specific challenges, from financial services to biotechnology and consumer electronics.\nAccepting invitations for launch event and eyeing future improvements\nLiquid AI says it is is optimizing its models for deployment on hardware from NVIDIA, AMD, Apple, Qualcomm, and Cerebras.\nWhile the models are still in the preview phase, Liquid AI invites early adopters and developers to test the models and provide feedback.\nLabonne noted that while things are “not perfect,” the feedback received during this phase will help the team refine their offerings in preparation for a full launch event on October 23, 2024, at MIT’s Kresge Auditorium in Cambridge, MA. The company is accepting\nRSVPs for attendees of that event in-person here.\nAs part of its commitment to transparency and scientific progress, Liquid says it will release a series of technical blog posts leading up to the product launch event.\nThe company also plans to engage in red-teaming efforts, encouraging users to test the limits of their models to improve future iterations.\nWith the introduction of Liquid Foundation Models, Liquid AI is positioning itself as a key player in the foundation model space. By combining state-of-the-art performance with unprecedented memory efficiency, LFMs offer a compelling alternative to traditional transformer-based models.\nDaily insights on business use cases with VB Daily\nIf you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.\nSubscribe Now\nRead our\nPrivacy Policy\nThanks for subscribing. Check out more\nVB newsletters here\n.\nAn error occured.\nThe AI Impact Tour Dates\nJoin leaders in enterprise AI for networking, insights, and engaging conversations at the upcoming stops of our AI Impact Tour. See if we're coming to your area!\nLearn More\n×\nAI Weekly\nYour weekly look at how applied AI is changing the tech world\nFirst Name\nLast Name\nCompany Name\nEmail\nSubscribe\nWe respect your privacy. Your email will only be used for sending our newsletter. You can unsubscribe at any time. Read our\nPrivacy Policy\n.\nThanks for subscribing. Check out more\nVB newsletters here\n.\nAn error occured.", 'image_urls': [{'url': 'https://venturebeat.com/wp-content/uploads/2024/09/66f9a9b9624c365c96251a0c_desktop-graph-2.png?w=800', 'score': 2}, {'url': 'https://venturebeat.com/wp-content/uploads/2024/09/66f9a9b9624c365c96251a0c_desktop-graph.png?w=800', 'score': 2}, {'url': 'https://venturebeat.com/wp-content/uploads/2024/09/Screenshot-2024-09-30-at-5.03.53%E2%80%AFPM.png?w=800', 'score': 1}], 'title': 'MIT spinoff Liquid debuts small, efficient non-transformer AI models | VentureBeat'}]